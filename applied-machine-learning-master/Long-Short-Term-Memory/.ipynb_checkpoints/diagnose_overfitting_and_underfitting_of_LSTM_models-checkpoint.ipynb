{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Diagnose Overfitting and Underfitting of LSTM Models\n",
    "It can be difficult to determine whether your Long Short-Term Memory model is performing well on your sequence prediction problem.\n",
    "\n",
    "You may be getting a good model skill score, but it is important to know whether your model is a good fit for your data or if it is underfit or overfit and could do better with a different configuration.\n",
    "\n",
    "In this tutorial, you will discover how you can diagnose the fit of your LSTM model on your sequence prediction problem.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "* How to gather and plot training history of LSTM models.\n",
    "* How to diagnose an underfit, good fit, and overfit model.\n",
    "* How to develop more robust diagnostics by averaging multiple model runs.\n",
    "\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Overview\n",
    "This tutorial is divided into 6 parts; they are:\n",
    "\n",
    "1. Training History in Keras\n",
    "2. Diagnostic Plots\n",
    "3. Underfit Example\n",
    "4. Good Fit Example\n",
    "5. Overfit Example\n",
    "6. Multiple Runs Example\n",
    "\n",
    "## 1. Training History in Keras\n",
    "You can learn a lot about the behavior of your model by reviewing its performance over time.\n",
    "\n",
    "LSTM models are trained by calling the fit() function. This function returns a variable called history that contains a trace of the loss and any other metrics specified during the compilation of the model. These scores are recorded at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if your model was compiled to optimize the log loss (binary_crossentropy) and measure accuracy each epoch, then the log loss and accuracy will be calculated and recorded in the history trace for each training epoch.\n",
    "\n",
    "Each score is accessed by a key in the history object returned from calling fit(). By default, the loss optimized when fitting the model is called “loss” and accuracy is called “acc“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=100)\n",
    "print(history.history['loss'])\n",
    "print(history.history['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also allows you to specify a separate validation dataset while fitting your model that can also be evaluated using the same loss and metrics.\n",
    "\n",
    "This can be done by setting the validation_split argument on fit() to use a portion of the training data as a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be done by setting the validation_data argument and passing a tuple of X and y datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "history = model.fit(X, Y, epochs=100, validation_data=(valX, valY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics evaluated on the validation dataset are keyed using the same names, with a “val_” prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.33)\n",
    "print(history.history['loss'])\n",
    "print(history.history['acc'])\n",
    "print(history.history['val_loss'])\n",
    "print(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diagnostic Plots\n",
    "The training history of your LSTM models can be used to diagnose the behavior of your model.\n",
    "\n",
    "You can plot the performance of your model using the Matplotlib library. For example, you can plot training loss vs test loss as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "...\n",
    "history = model.fit(X, Y, epochs=100, validation_data=(valX, valY))\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and reviewing these plots can help to inform you about possible new configurations to try in order to get better performance from your model.\n",
    "\n",
    "Next, we will look at some examples. We will consider model skill on the train and validation sets in terms of loss that is minimized. You can use any metric that is meaningful on your problem.\n",
    "\n",
    "## 3. Underfit Example\n",
    "An underfit model is one that is demonstrated to perform well on the training dataset and poor on the test dataset.\n",
    "\n",
    "This can be diagnosed from a plot where the training loss is lower than the validation loss, and the validation loss has a trend that suggests further improvements are possible.\n",
    "\n",
    "A small contrived example of an underfit LSTM model is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 224ms/step - loss: 0.1030 - val_loss: 0.6009\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 872us/step - loss: 0.1014 - val_loss: 0.5954\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.5898\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.0983 - val_loss: 0.5846\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0969 - val_loss: 0.5791\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0954 - val_loss: 0.5737\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.5682\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.5628\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.5574\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.5520\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.5467\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.5413\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0852 - val_loss: 0.5361\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.5308\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.5256\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.5204\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.5152\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.5100\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.5049\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.4998\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.4948\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.4897\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.4847\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.4798\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.4748\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.4699\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 985us/step - loss: 0.0669 - val_loss: 0.4650\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 937us/step - loss: 0.0656 - val_loss: 0.4601\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.4553\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0633 - val_loss: 0.4505\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0621 - val_loss: 0.4458\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0610 - val_loss: 0.4410\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 876us/step - loss: 0.0598 - val_loss: 0.4363\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0587 - val_loss: 0.4317\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.0576 - val_loss: 0.4270\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 730us/step - loss: 0.0565 - val_loss: 0.4224\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.4179\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.4133\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.4088\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.4043\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0513 - val_loss: 0.3999\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.3954\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.0493 - val_loss: 0.3911\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.0484 - val_loss: 0.3867\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 915us/step - loss: 0.0474 - val_loss: 0.3824\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0465 - val_loss: 0.3781\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.3739\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.3697\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 769us/step - loss: 0.0437 - val_loss: 0.3655\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 779us/step - loss: 0.0429 - val_loss: 0.3613\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 945us/step - loss: 0.0420 - val_loss: 0.3572\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.3532\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.3491\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.3451\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0387 - val_loss: 0.3411\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.3372\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.3333\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0363 - val_loss: 0.3294\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0355 - val_loss: 0.3256\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0348 - val_loss: 0.3218\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 963us/step - loss: 0.0341 - val_loss: 0.3180\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.3143\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 962us/step - loss: 0.0327 - val_loss: 0.3106\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 810us/step - loss: 0.0320 - val_loss: 0.3069\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.0313 - val_loss: 0.3033\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 952us/step - loss: 0.0306 - val_loss: 0.2997\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 967us/step - loss: 0.0300 - val_loss: 0.2961\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 948us/step - loss: 0.0294 - val_loss: 0.2926\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.2891\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.2857\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0275 - val_loss: 0.2823\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.2789\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0264 - val_loss: 0.2755\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0258 - val_loss: 0.2722\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0253 - val_loss: 0.2690\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 938us/step - loss: 0.0248 - val_loss: 0.2657\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.0242 - val_loss: 0.2625\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 920us/step - loss: 0.0237 - val_loss: 0.2594\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0232 - val_loss: 0.2563\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.2532\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.2501\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.2471\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.2442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.2412\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.2383\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.2355\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2326\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.2299\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0189 - val_loss: 0.2271\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 972us/step - loss: 0.0186 - val_loss: 0.2244\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 931us/step - loss: 0.0182 - val_loss: 0.2217\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.2190\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.2164\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.2139\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2113\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.2088\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.2064\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.2040\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.2016\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.1992\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b2eac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "%matplotlib inline\n",
    "\n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=100, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example produces a plot of train and validation loss showing the characteristic of an underfit model. In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "In this case, performance may be improved by increasing the number of training epochs.\n",
    "\n",
    "Alternately, a model may be underfit if performance on the training set is better than the validation set and performance has leveled off. Below is an example of an an underfit model with insufficient memory cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 236ms/step - loss: 0.2557 - val_loss: 0.6502\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2440 - val_loss: 0.6387\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2323 - val_loss: 0.6272\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 928us/step - loss: 0.2207 - val_loss: 0.6157\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2090 - val_loss: 0.6043\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1973 - val_loss: 0.5928\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1856 - val_loss: 0.5813\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.5699\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1623 - val_loss: 0.5584\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1527 - val_loss: 0.5515\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1485 - val_loss: 0.5446\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1443 - val_loss: 0.5377\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1401 - val_loss: 0.5307\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.5238\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 880us/step - loss: 0.1317 - val_loss: 0.5169\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1275 - val_loss: 0.5100\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 789us/step - loss: 0.1233 - val_loss: 0.5031\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1191 - val_loss: 0.4962\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 739us/step - loss: 0.1149 - val_loss: 0.4893\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.4823\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 869us/step - loss: 0.1085 - val_loss: 0.4800\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 925us/step - loss: 0.1080 - val_loss: 0.4776\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 973us/step - loss: 0.1075 - val_loss: 0.4753\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1071 - val_loss: 0.4729\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 865us/step - loss: 0.1066 - val_loss: 0.4706\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1061 - val_loss: 0.4682\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 858us/step - loss: 0.1056 - val_loss: 0.4658\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.1051 - val_loss: 0.4635\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1046 - val_loss: 0.4611\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.1041 - val_loss: 0.4588\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 931us/step - loss: 0.1036 - val_loss: 0.4564\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1032 - val_loss: 0.4540\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.4517\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.4493\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.4470\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.1012 - val_loss: 0.4446\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.4423\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 963us/step - loss: 0.1002 - val_loss: 0.4399\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0998 - val_loss: 0.4376\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0993 - val_loss: 0.4352\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0988 - val_loss: 0.4328\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0983 - val_loss: 0.4305\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0978 - val_loss: 0.4281\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0973 - val_loss: 0.4258\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0969 - val_loss: 0.4234\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0964 - val_loss: 0.4211\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0959 - val_loss: 0.4187\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0954 - val_loss: 0.4164\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0949 - val_loss: 0.4140\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.4117\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0939 - val_loss: 0.4093\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.4070\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.0935 - val_loss: 0.4092\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.4068\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.4090\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.4067\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0934 - val_loss: 0.4089\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.4065\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.4088\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.4064\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.4086\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.4063\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0932 - val_loss: 0.4085\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.4061\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.4083\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.4060\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.4082\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0931 - val_loss: 0.4059\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.4081\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.4057\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.4079\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0930 - val_loss: 0.4056\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 967us/step - loss: 0.0928 - val_loss: 0.4078\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.4054\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.4077\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0929 - val_loss: 0.4053\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.4075\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 919us/step - loss: 0.0929 - val_loss: 0.4052\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.4074\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.4050\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.4072\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 979us/step - loss: 0.0928 - val_loss: 0.4049\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.4047\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.4070\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.4046\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.4068\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.4045\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.4067\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.4043\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.4065\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.4042\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.4064\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.4040\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.4063\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.4039\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.4061\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.4038\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.4060\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.4036\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.4058\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0923 - val_loss: 0.4035\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.4057\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.4033\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.4010\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.4032\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.4008\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.4030\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.4007\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.4029\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.4005\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.4028\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.0916 - val_loss: 0.4004\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0919 - val_loss: 0.4026\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.4003\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.4025\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.4001\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0918 - val_loss: 0.4023\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.4000\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0917 - val_loss: 0.4022\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.3998\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.4020\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.3997\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.4019\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0913 - val_loss: 0.3995\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.4018\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.3994\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.4016\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.3992\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0914 - val_loss: 0.4015\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.3991\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.4013\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.3990\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.4012\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.3988\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.4010\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.3987\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.4009\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.0909 - val_loss: 0.3985\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.4007\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.3984\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0909 - val_loss: 0.4006\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.3982\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.0909 - val_loss: 0.4004\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.3981\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.4003\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.3979\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.4002\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0907 - val_loss: 0.3978\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.4000\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.3976\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.3999\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.3975\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.3997\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0906 - val_loss: 0.3973\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.3996\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0905 - val_loss: 0.3972\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.3994\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0905 - val_loss: 0.3970\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.3993\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.3969\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.3991\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0904 - val_loss: 0.3967\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.3990\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.3966\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.3988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.3965\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.3987\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.3963\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.3985\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.3962\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.3984\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 979us/step - loss: 0.0901 - val_loss: 0.3960\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0898 - val_loss: 0.3982\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.3959\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.3981\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 937us/step - loss: 0.0900 - val_loss: 0.3957\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.3979\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 981us/step - loss: 0.0900 - val_loss: 0.3956\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.3978\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.3954\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.3976\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.3953\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.3975\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0898 - val_loss: 0.3951\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.3973\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0898 - val_loss: 0.3949\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.3972\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0897 - val_loss: 0.3948\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.3924\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.3946\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.3923\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.3945\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.3921\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.3943\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.3920\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.3942\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.3918\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0894 - val_loss: 0.3940\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.3917\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.3939\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.3915\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.3937\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.3914\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.3936\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0888 - val_loss: 0.3912\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0891 - val_loss: 0.3934\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0888 - val_loss: 0.3910\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.3933\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.3909\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.3931\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.3907\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 898us/step - loss: 0.0888 - val_loss: 0.3930\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 979us/step - loss: 0.0886 - val_loss: 0.3906\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.0888 - val_loss: 0.3928\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.3904\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.3927\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.0885 - val_loss: 0.3903\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.3925\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.3901\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 881us/step - loss: 0.0885 - val_loss: 0.3923\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 893us/step - loss: 0.0884 - val_loss: 0.3900\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0885 - val_loss: 0.3922\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0883 - val_loss: 0.3898\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0884 - val_loss: 0.3920\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 819us/step - loss: 0.0883 - val_loss: 0.3897\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0883 - val_loss: 0.3919\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.3895\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.3917\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0882 - val_loss: 0.3893\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.0882 - val_loss: 0.3916\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.3892\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.3914\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.3890\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 841us/step - loss: 0.0880 - val_loss: 0.3912\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 899us/step - loss: 0.0880 - val_loss: 0.3889\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 837us/step - loss: 0.0879 - val_loss: 0.3911\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0880 - val_loss: 0.3887\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 921us/step - loss: 0.0879 - val_loss: 0.3909\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 925us/step - loss: 0.0879 - val_loss: 0.3886\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0878 - val_loss: 0.3908\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0879 - val_loss: 0.3884\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0877 - val_loss: 0.3906\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0878 - val_loss: 0.3882\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 834us/step - loss: 0.0876 - val_loss: 0.3905\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.0878 - val_loss: 0.3881\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 917us/step - loss: 0.0876 - val_loss: 0.3903\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.3879\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0875 - val_loss: 0.3901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.3878\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 966us/step - loss: 0.0874 - val_loss: 0.3900\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0876 - val_loss: 0.3876\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 926us/step - loss: 0.0873 - val_loss: 0.3898\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 905us/step - loss: 0.0876 - val_loss: 0.3874\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 882us/step - loss: 0.0872 - val_loss: 0.3897\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 880us/step - loss: 0.0875 - val_loss: 0.3873\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 922us/step - loss: 0.0872 - val_loss: 0.3895\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 930us/step - loss: 0.0874 - val_loss: 0.3871\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.3893\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0874 - val_loss: 0.3870\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.3892\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.3868\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.3890\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.3866\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.3889\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 807us/step - loss: 0.0872 - val_loss: 0.3865\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 942us/step - loss: 0.0868 - val_loss: 0.3887\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0872 - val_loss: 0.3863\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 807us/step - loss: 0.0867 - val_loss: 0.3885\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.0871 - val_loss: 0.3861\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0866 - val_loss: 0.3884\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 860us/step - loss: 0.0871 - val_loss: 0.3860\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.3836\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.3858\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.3834\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.3857\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 915us/step - loss: 0.0865 - val_loss: 0.3833\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0868 - val_loss: 0.3855\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 839us/step - loss: 0.0864 - val_loss: 0.3831\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0868 - val_loss: 0.3853\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0864 - val_loss: 0.3829\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 959us/step - loss: 0.0867 - val_loss: 0.3852\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.3828\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0866 - val_loss: 0.3850\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 870us/step - loss: 0.0862 - val_loss: 0.3826\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 937us/step - loss: 0.0865 - val_loss: 0.3848\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.3825\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.3847\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.3823\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.3845\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0861 - val_loss: 0.3821\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 795us/step - loss: 0.0863 - val_loss: 0.3844\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 914us/step - loss: 0.0860 - val_loss: 0.3820\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.3842\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 912us/step - loss: 0.0860 - val_loss: 0.3818\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 912us/step - loss: 0.0861 - val_loss: 0.3840\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.3816\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 922us/step - loss: 0.0861 - val_loss: 0.3839\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 915us/step - loss: 0.0859 - val_loss: 0.3815\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0860 - val_loss: 0.3837\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b1aac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "%matplotlib inline\n",
    " \n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mae', optimizer='sgd')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example shows the characteristic of an underfit model that appears under-provisioned.\n",
    "\n",
    "In this case, performance may be improved by increasing the capacity of the model, such as the number of memory cells in a hidden layer or number of hidden layers.\n",
    "\n",
    "## 4. Good Fit Example\n",
    "A good fit is a case where the performance of the model is good on both the train and validation sets.\n",
    "\n",
    "This can be diagnosed from a plot where the train and validation loss decrease and stabilize around the same point.\n",
    "\n",
    "The small example below demonstrates an LSTM model with a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/800\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 0.1201 - val_loss: 0.7273\n",
      "Epoch 2/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1187 - val_loss: 0.7225\n",
      "Epoch 3/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.7178\n",
      "Epoch 4/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1159 - val_loss: 0.7130\n",
      "Epoch 5/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.7083\n",
      "Epoch 6/800\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.1132 - val_loss: 0.7036\n",
      "Epoch 7/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1119 - val_loss: 0.6989\n",
      "Epoch 8/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1106 - val_loss: 0.6943\n",
      "Epoch 9/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1093 - val_loss: 0.6897\n",
      "Epoch 10/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1080 - val_loss: 0.6851\n",
      "Epoch 11/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1067 - val_loss: 0.6805\n",
      "Epoch 12/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1054 - val_loss: 0.6760\n",
      "Epoch 13/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1042 - val_loss: 0.6715\n",
      "Epoch 14/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1029 - val_loss: 0.6670\n",
      "Epoch 15/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.6625\n",
      "Epoch 16/800\n",
      "5/5 [==============================] - 0s 966us/step - loss: 0.1004 - val_loss: 0.6581\n",
      "Epoch 17/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0992 - val_loss: 0.6537\n",
      "Epoch 18/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0980 - val_loss: 0.6493\n",
      "Epoch 19/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.6449\n",
      "Epoch 20/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.6406\n",
      "Epoch 21/800\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.0945 - val_loss: 0.6363\n",
      "Epoch 22/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0933 - val_loss: 0.6320\n",
      "Epoch 23/800\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0922 - val_loss: 0.6277\n",
      "Epoch 24/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.6235\n",
      "Epoch 25/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.6193\n",
      "Epoch 26/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0888 - val_loss: 0.6151\n",
      "Epoch 27/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.6110\n",
      "Epoch 28/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.6068\n",
      "Epoch 29/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.6027\n",
      "Epoch 30/800\n",
      "5/5 [==============================] - 0s 942us/step - loss: 0.0844 - val_loss: 0.5987\n",
      "Epoch 31/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.5946\n",
      "Epoch 32/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.5906\n",
      "Epoch 33/800\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0813 - val_loss: 0.5867\n",
      "Epoch 34/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.5827\n",
      "Epoch 35/800\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.0792 - val_loss: 0.5788\n",
      "Epoch 36/800\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.0782 - val_loss: 0.5749\n",
      "Epoch 37/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.5710\n",
      "Epoch 38/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.5671\n",
      "Epoch 39/800\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0753 - val_loss: 0.5633\n",
      "Epoch 40/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.5595\n",
      "Epoch 41/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.5557\n",
      "Epoch 42/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.5519\n",
      "Epoch 43/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.5482\n",
      "Epoch 44/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.5444\n",
      "Epoch 45/800\n",
      "5/5 [==============================] - 0s 928us/step - loss: 0.0696 - val_loss: 0.5407\n",
      "Epoch 46/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.5370\n",
      "Epoch 47/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.5334\n",
      "Epoch 48/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.5297\n",
      "Epoch 49/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.5261\n",
      "Epoch 50/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.5225\n",
      "Epoch 51/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.5189\n",
      "Epoch 52/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0634 - val_loss: 0.5154\n",
      "Epoch 53/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.5118\n",
      "Epoch 54/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.5083\n",
      "Epoch 55/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.5048\n",
      "Epoch 56/800\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0601 - val_loss: 0.5013\n",
      "Epoch 57/800\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0593 - val_loss: 0.4978\n",
      "Epoch 58/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.4944\n",
      "Epoch 59/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.4909\n",
      "Epoch 60/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.4875\n",
      "Epoch 61/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.4840\n",
      "Epoch 62/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0554 - val_loss: 0.4806\n",
      "Epoch 63/800\n",
      "5/5 [==============================] - 0s 886us/step - loss: 0.0546 - val_loss: 0.4772\n",
      "Epoch 64/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0538 - val_loss: 0.4739\n",
      "Epoch 65/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.4705\n",
      "Epoch 66/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0524 - val_loss: 0.4672\n",
      "Epoch 67/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.4638\n",
      "Epoch 68/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0509 - val_loss: 0.4605\n",
      "Epoch 69/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.4572\n",
      "Epoch 70/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.4539\n",
      "Epoch 71/800\n",
      "5/5 [==============================] - 0s 931us/step - loss: 0.0488 - val_loss: 0.4507\n",
      "Epoch 72/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.4474\n",
      "Epoch 73/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.4442\n",
      "Epoch 74/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.4410\n",
      "Epoch 75/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.4377\n",
      "Epoch 76/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.4345\n",
      "Epoch 77/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.4314\n",
      "Epoch 78/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.4282\n",
      "Epoch 79/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.4250\n",
      "Epoch 80/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.4219\n",
      "Epoch 81/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.4187\n",
      "Epoch 82/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.4156\n",
      "Epoch 83/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.4125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.4094\n",
      "Epoch 85/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.4063\n",
      "Epoch 86/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.4033\n",
      "Epoch 87/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.4002\n",
      "Epoch 88/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0381 - val_loss: 0.3972\n",
      "Epoch 89/800\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.0375 - val_loss: 0.3942\n",
      "Epoch 90/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.3912\n",
      "Epoch 91/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.3882\n",
      "Epoch 92/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.3852\n",
      "Epoch 93/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.3822\n",
      "Epoch 94/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.3792\n",
      "Epoch 95/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0343 - val_loss: 0.3763\n",
      "Epoch 96/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.3734\n",
      "Epoch 97/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.3705\n",
      "Epoch 98/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.3676\n",
      "Epoch 99/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.3647\n",
      "Epoch 100/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.3618\n",
      "Epoch 101/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.3590\n",
      "Epoch 102/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.3561\n",
      "Epoch 103/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0304 - val_loss: 0.3533\n",
      "Epoch 104/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0300 - val_loss: 0.3505\n",
      "Epoch 105/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.3477\n",
      "Epoch 106/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.3450\n",
      "Epoch 107/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.3422\n",
      "Epoch 108/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0282 - val_loss: 0.3395\n",
      "Epoch 109/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.3368\n",
      "Epoch 110/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.3341\n",
      "Epoch 111/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.3314\n",
      "Epoch 112/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.3287\n",
      "Epoch 113/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.3261\n",
      "Epoch 114/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.3235\n",
      "Epoch 115/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.3209\n",
      "Epoch 116/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.3183\n",
      "Epoch 117/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.3157\n",
      "Epoch 118/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.3131\n",
      "Epoch 119/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0241 - val_loss: 0.3106\n",
      "Epoch 120/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.3081\n",
      "Epoch 121/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.3056\n",
      "Epoch 122/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.3032\n",
      "Epoch 123/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.3007\n",
      "Epoch 124/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.2983\n",
      "Epoch 125/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.2959\n",
      "Epoch 126/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.2935\n",
      "Epoch 127/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.2911\n",
      "Epoch 128/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.2888\n",
      "Epoch 129/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.2865\n",
      "Epoch 130/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.2842\n",
      "Epoch 131/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.2819\n",
      "Epoch 132/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.2796\n",
      "Epoch 133/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.2774\n",
      "Epoch 134/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.2752\n",
      "Epoch 135/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2730\n",
      "Epoch 136/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2708\n",
      "Epoch 137/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.2687\n",
      "Epoch 138/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.2666\n",
      "Epoch 139/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.2645\n",
      "Epoch 140/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.2624\n",
      "Epoch 141/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.2604\n",
      "Epoch 142/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.2583\n",
      "Epoch 143/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.2563\n",
      "Epoch 144/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.2544\n",
      "Epoch 145/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2524\n",
      "Epoch 146/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.2505\n",
      "Epoch 147/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.2486\n",
      "Epoch 148/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.2467\n",
      "Epoch 149/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.2448\n",
      "Epoch 150/800\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.0169 - val_loss: 0.2430\n",
      "Epoch 151/800\n",
      "5/5 [==============================] - 0s 905us/step - loss: 0.0168 - val_loss: 0.2412\n",
      "Epoch 152/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2394\n",
      "Epoch 153/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2377\n",
      "Epoch 154/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.2359\n",
      "Epoch 155/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.2342\n",
      "Epoch 156/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.2325\n",
      "Epoch 157/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2308\n",
      "Epoch 158/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.2292\n",
      "Epoch 159/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.2276\n",
      "Epoch 160/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.2260\n",
      "Epoch 161/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.2244\n",
      "Epoch 162/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2229\n",
      "Epoch 163/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.2214\n",
      "Epoch 164/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2199\n",
      "Epoch 165/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2184\n",
      "Epoch 166/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.2155\n",
      "Epoch 168/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2141\n",
      "Epoch 169/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.2127\n",
      "Epoch 170/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.2114\n",
      "Epoch 171/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.2100\n",
      "Epoch 172/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.2087\n",
      "Epoch 173/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.2074\n",
      "Epoch 174/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2061\n",
      "Epoch 175/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.2049\n",
      "Epoch 176/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2036\n",
      "Epoch 177/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2024\n",
      "Epoch 178/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2012\n",
      "Epoch 179/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.2001\n",
      "Epoch 180/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1989\n",
      "Epoch 181/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1978\n",
      "Epoch 182/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1967\n",
      "Epoch 183/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0140 - val_loss: 0.1956\n",
      "Epoch 184/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1945\n",
      "Epoch 185/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1935\n",
      "Epoch 186/800\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0138 - val_loss: 0.1924\n",
      "Epoch 187/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1914\n",
      "Epoch 188/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1904\n",
      "Epoch 189/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1894\n",
      "Epoch 190/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1885\n",
      "Epoch 191/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1875\n",
      "Epoch 192/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1866\n",
      "Epoch 193/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1857\n",
      "Epoch 194/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1848\n",
      "Epoch 195/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1839\n",
      "Epoch 196/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1830\n",
      "Epoch 197/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1822\n",
      "Epoch 198/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1813\n",
      "Epoch 199/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.1805\n",
      "Epoch 200/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1797\n",
      "Epoch 201/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1789\n",
      "Epoch 202/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1781\n",
      "Epoch 203/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1773\n",
      "Epoch 204/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1766\n",
      "Epoch 205/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1758\n",
      "Epoch 206/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1751\n",
      "Epoch 207/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1744\n",
      "Epoch 208/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1737\n",
      "Epoch 209/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1730\n",
      "Epoch 210/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1723\n",
      "Epoch 211/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1716\n",
      "Epoch 212/800\n",
      "5/5 [==============================] - 0s 948us/step - loss: 0.0128 - val_loss: 0.1710\n",
      "Epoch 213/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1703\n",
      "Epoch 214/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1697\n",
      "Epoch 215/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1690\n",
      "Epoch 216/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1684\n",
      "Epoch 217/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1678\n",
      "Epoch 218/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1672\n",
      "Epoch 219/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1666\n",
      "Epoch 220/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1660\n",
      "Epoch 221/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1654\n",
      "Epoch 222/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1648\n",
      "Epoch 223/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1642\n",
      "Epoch 224/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1637\n",
      "Epoch 225/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1631\n",
      "Epoch 226/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1626\n",
      "Epoch 227/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1620\n",
      "Epoch 228/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1615\n",
      "Epoch 229/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1609\n",
      "Epoch 230/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1604\n",
      "Epoch 231/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1599\n",
      "Epoch 232/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1594\n",
      "Epoch 233/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1588\n",
      "Epoch 234/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1583\n",
      "Epoch 235/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1578\n",
      "Epoch 236/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1573\n",
      "Epoch 237/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1568\n",
      "Epoch 238/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1563\n",
      "Epoch 239/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1559\n",
      "Epoch 240/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1554\n",
      "Epoch 241/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1549\n",
      "Epoch 242/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1544\n",
      "Epoch 243/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1539\n",
      "Epoch 244/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1535\n",
      "Epoch 245/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1530\n",
      "Epoch 246/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1525\n",
      "Epoch 247/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1521\n",
      "Epoch 248/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1516\n",
      "Epoch 249/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1507\n",
      "Epoch 251/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1502\n",
      "Epoch 252/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1498\n",
      "Epoch 253/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1493\n",
      "Epoch 254/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1489\n",
      "Epoch 255/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1484\n",
      "Epoch 256/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1480\n",
      "Epoch 257/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1475\n",
      "Epoch 258/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1471\n",
      "Epoch 259/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1467\n",
      "Epoch 260/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1462\n",
      "Epoch 261/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1458\n",
      "Epoch 262/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1453\n",
      "Epoch 263/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1449\n",
      "Epoch 264/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1445\n",
      "Epoch 265/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1440\n",
      "Epoch 266/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1436\n",
      "Epoch 267/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1432\n",
      "Epoch 268/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1427\n",
      "Epoch 269/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1423\n",
      "Epoch 270/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1418\n",
      "Epoch 271/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1414\n",
      "Epoch 272/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1410\n",
      "Epoch 273/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1406\n",
      "Epoch 274/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1401\n",
      "Epoch 275/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1397\n",
      "Epoch 276/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1393\n",
      "Epoch 277/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1388\n",
      "Epoch 278/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1384\n",
      "Epoch 279/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1380\n",
      "Epoch 280/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1375\n",
      "Epoch 281/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1371\n",
      "Epoch 282/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1367\n",
      "Epoch 283/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1362\n",
      "Epoch 284/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1358\n",
      "Epoch 285/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1354\n",
      "Epoch 286/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1350\n",
      "Epoch 287/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1345\n",
      "Epoch 288/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1341\n",
      "Epoch 289/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1337\n",
      "Epoch 290/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1332\n",
      "Epoch 291/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1328\n",
      "Epoch 292/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1324\n",
      "Epoch 293/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1319\n",
      "Epoch 294/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1315\n",
      "Epoch 295/800\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0103 - val_loss: 0.1311\n",
      "Epoch 296/800\n",
      "5/5 [==============================] - 0s 928us/step - loss: 0.0103 - val_loss: 0.1306\n",
      "Epoch 297/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1302\n",
      "Epoch 298/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1298\n",
      "Epoch 299/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1293\n",
      "Epoch 300/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1289\n",
      "Epoch 301/800\n",
      "5/5 [==============================] - 0s 994us/step - loss: 0.0101 - val_loss: 0.1285\n",
      "Epoch 302/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1281\n",
      "Epoch 303/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1276\n",
      "Epoch 304/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1272\n",
      "Epoch 305/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1268\n",
      "Epoch 306/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1263\n",
      "Epoch 307/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1259\n",
      "Epoch 308/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1255\n",
      "Epoch 309/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1250\n",
      "Epoch 310/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1246\n",
      "Epoch 311/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0098 - val_loss: 0.1242\n",
      "Epoch 312/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1237\n",
      "Epoch 313/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1233\n",
      "Epoch 314/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1229\n",
      "Epoch 315/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1224\n",
      "Epoch 316/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0097 - val_loss: 0.1220\n",
      "Epoch 317/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1215\n",
      "Epoch 318/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1211\n",
      "Epoch 319/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1207\n",
      "Epoch 320/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1202\n",
      "Epoch 321/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1198\n",
      "Epoch 322/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1194\n",
      "Epoch 323/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1189\n",
      "Epoch 324/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1185\n",
      "Epoch 325/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1181\n",
      "Epoch 326/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1176\n",
      "Epoch 327/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1172\n",
      "Epoch 328/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1167\n",
      "Epoch 329/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1163\n",
      "Epoch 330/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1159\n",
      "Epoch 331/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1154\n",
      "Epoch 332/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1146\n",
      "Epoch 334/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1141\n",
      "Epoch 335/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1137\n",
      "Epoch 336/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1132\n",
      "Epoch 337/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1128\n",
      "Epoch 338/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1124\n",
      "Epoch 339/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1119\n",
      "Epoch 340/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1115\n",
      "Epoch 341/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1111\n",
      "Epoch 342/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1106\n",
      "Epoch 343/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1102\n",
      "Epoch 344/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1097\n",
      "Epoch 345/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1093\n",
      "Epoch 346/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1089\n",
      "Epoch 347/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1084\n",
      "Epoch 348/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1080\n",
      "Epoch 349/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1075\n",
      "Epoch 350/800\n",
      "5/5 [==============================] - 0s 891us/step - loss: 0.0086 - val_loss: 0.1071\n",
      "Epoch 351/800\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0086 - val_loss: 0.1067\n",
      "Epoch 352/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1062\n",
      "Epoch 353/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1058\n",
      "Epoch 354/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1053\n",
      "Epoch 355/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1049\n",
      "Epoch 356/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1045\n",
      "Epoch 357/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1040\n",
      "Epoch 358/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1036\n",
      "Epoch 359/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1031\n",
      "Epoch 360/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1027\n",
      "Epoch 361/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1023\n",
      "Epoch 362/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1018\n",
      "Epoch 363/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1014\n",
      "Epoch 364/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1009\n",
      "Epoch 365/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1005\n",
      "Epoch 366/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1001\n",
      "Epoch 367/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0996\n",
      "Epoch 368/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0992\n",
      "Epoch 369/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0987\n",
      "Epoch 370/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0983\n",
      "Epoch 371/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0979\n",
      "Epoch 372/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0974\n",
      "Epoch 373/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0970\n",
      "Epoch 374/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0965\n",
      "Epoch 375/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0961\n",
      "Epoch 376/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0957\n",
      "Epoch 377/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0952\n",
      "Epoch 378/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0948\n",
      "Epoch 379/800\n",
      "5/5 [==============================] - 0s 921us/step - loss: 0.0077 - val_loss: 0.0943\n",
      "Epoch 380/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0939\n",
      "Epoch 381/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0935\n",
      "Epoch 382/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0930\n",
      "Epoch 383/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0926\n",
      "Epoch 384/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0921\n",
      "Epoch 385/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0917\n",
      "Epoch 386/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0913\n",
      "Epoch 387/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0908\n",
      "Epoch 388/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0904\n",
      "Epoch 389/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0899\n",
      "Epoch 390/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0895\n",
      "Epoch 391/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0891\n",
      "Epoch 392/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0886\n",
      "Epoch 393/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0882\n",
      "Epoch 394/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0877\n",
      "Epoch 395/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0873\n",
      "Epoch 396/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0869\n",
      "Epoch 397/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0864\n",
      "Epoch 398/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0860\n",
      "Epoch 399/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0856\n",
      "Epoch 400/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0851\n",
      "Epoch 401/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0847\n",
      "Epoch 402/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0842\n",
      "Epoch 403/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0838\n",
      "Epoch 404/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0834\n",
      "Epoch 405/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0829\n",
      "Epoch 406/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0825\n",
      "Epoch 407/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0821\n",
      "Epoch 408/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0816\n",
      "Epoch 409/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0812\n",
      "Epoch 410/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0808\n",
      "Epoch 411/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0803\n",
      "Epoch 412/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0799\n",
      "Epoch 413/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0794\n",
      "Epoch 414/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0790\n",
      "Epoch 415/800\n",
      "5/5 [==============================] - 0s 867us/step - loss: 0.0065 - val_loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0781\n",
      "Epoch 417/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0777\n",
      "Epoch 418/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0773\n",
      "Epoch 419/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0768\n",
      "Epoch 420/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0764\n",
      "Epoch 421/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0760\n",
      "Epoch 422/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0756\n",
      "Epoch 423/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0751\n",
      "Epoch 424/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0747\n",
      "Epoch 425/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0743\n",
      "Epoch 426/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0738\n",
      "Epoch 427/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0734\n",
      "Epoch 428/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0730\n",
      "Epoch 429/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0725\n",
      "Epoch 430/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0721\n",
      "Epoch 431/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.0717\n",
      "Epoch 432/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0713\n",
      "Epoch 433/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0708\n",
      "Epoch 434/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0704\n",
      "Epoch 435/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0700\n",
      "Epoch 436/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0696\n",
      "Epoch 437/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0691\n",
      "Epoch 438/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0058 - val_loss: 0.0687\n",
      "Epoch 439/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0683\n",
      "Epoch 440/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 0.0679\n",
      "Epoch 441/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0674\n",
      "Epoch 442/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0670\n",
      "Epoch 443/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0666\n",
      "Epoch 444/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0662\n",
      "Epoch 445/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0657\n",
      "Epoch 446/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0653\n",
      "Epoch 447/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0649\n",
      "Epoch 448/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0645\n",
      "Epoch 449/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0641\n",
      "Epoch 450/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0636\n",
      "Epoch 451/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0632\n",
      "Epoch 452/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0628\n",
      "Epoch 453/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0624\n",
      "Epoch 454/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0620\n",
      "Epoch 455/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0616\n",
      "Epoch 456/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0612\n",
      "Epoch 457/800\n",
      "5/5 [==============================] - 0s 910us/step - loss: 0.0052 - val_loss: 0.0607\n",
      "Epoch 458/800\n",
      "5/5 [==============================] - 0s 918us/step - loss: 0.0051 - val_loss: 0.0603\n",
      "Epoch 459/800\n",
      "5/5 [==============================] - 0s 940us/step - loss: 0.0051 - val_loss: 0.0599\n",
      "Epoch 460/800\n",
      "5/5 [==============================] - 0s 948us/step - loss: 0.0051 - val_loss: 0.0595\n",
      "Epoch 461/800\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0050 - val_loss: 0.0591\n",
      "Epoch 462/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0587\n",
      "Epoch 463/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0583\n",
      "Epoch 464/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0579\n",
      "Epoch 465/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0575\n",
      "Epoch 466/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0570\n",
      "Epoch 467/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0566\n",
      "Epoch 468/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0562\n",
      "Epoch 469/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0558\n",
      "Epoch 470/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0554\n",
      "Epoch 471/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0550\n",
      "Epoch 472/800\n",
      "5/5 [==============================] - 0s 952us/step - loss: 0.0047 - val_loss: 0.0546\n",
      "Epoch 473/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0542\n",
      "Epoch 474/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0538\n",
      "Epoch 475/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0534\n",
      "Epoch 476/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0530\n",
      "Epoch 477/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0526\n",
      "Epoch 478/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0522\n",
      "Epoch 479/800\n",
      "5/5 [==============================] - 0s 977us/step - loss: 0.0045 - val_loss: 0.0518\n",
      "Epoch 480/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0514\n",
      "Epoch 481/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0510\n",
      "Epoch 482/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0507\n",
      "Epoch 483/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0503\n",
      "Epoch 484/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0499\n",
      "Epoch 485/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0495\n",
      "Epoch 486/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0491\n",
      "Epoch 487/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0487\n",
      "Epoch 488/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0042 - val_loss: 0.0483\n",
      "Epoch 489/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0479\n",
      "Epoch 490/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0476\n",
      "Epoch 491/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0472\n",
      "Epoch 492/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0041 - val_loss: 0.0468\n",
      "Epoch 493/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0464\n",
      "Epoch 494/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0460\n",
      "Epoch 495/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0456\n",
      "Epoch 496/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0453\n",
      "Epoch 497/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0449\n",
      "Epoch 498/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0441\n",
      "Epoch 500/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0438\n",
      "Epoch 501/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0434\n",
      "Epoch 502/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0430\n",
      "Epoch 503/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0427\n",
      "Epoch 504/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0423\n",
      "Epoch 505/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0419\n",
      "Epoch 506/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0416\n",
      "Epoch 507/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0412\n",
      "Epoch 508/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0408\n",
      "Epoch 509/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0405\n",
      "Epoch 510/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0401\n",
      "Epoch 511/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0398\n",
      "Epoch 512/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0394\n",
      "Epoch 513/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0390\n",
      "Epoch 514/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0387\n",
      "Epoch 515/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0383\n",
      "Epoch 516/800\n",
      "5/5 [==============================] - 0s 969us/step - loss: 0.0034 - val_loss: 0.0380\n",
      "Epoch 517/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0376\n",
      "Epoch 518/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0373\n",
      "Epoch 519/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0369\n",
      "Epoch 520/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0366\n",
      "Epoch 521/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0362\n",
      "Epoch 522/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0359\n",
      "Epoch 523/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0356\n",
      "Epoch 524/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0352\n",
      "Epoch 525/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0349\n",
      "Epoch 526/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0345\n",
      "Epoch 527/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0342\n",
      "Epoch 528/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0339\n",
      "Epoch 529/800\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0031 - val_loss: 0.0335\n",
      "Epoch 530/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0332\n",
      "Epoch 531/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0329\n",
      "Epoch 532/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0325\n",
      "Epoch 533/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0322\n",
      "Epoch 534/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0319\n",
      "Epoch 535/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0316\n",
      "Epoch 536/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0312\n",
      "Epoch 537/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0309\n",
      "Epoch 538/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0306\n",
      "Epoch 539/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0303\n",
      "Epoch 540/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0300\n",
      "Epoch 541/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0297\n",
      "Epoch 542/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0293\n",
      "Epoch 543/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0290\n",
      "Epoch 544/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0287\n",
      "Epoch 545/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0284\n",
      "Epoch 546/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0281\n",
      "Epoch 547/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0278\n",
      "Epoch 548/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0275\n",
      "Epoch 549/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0272\n",
      "Epoch 550/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0269\n",
      "Epoch 551/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0266\n",
      "Epoch 552/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0263\n",
      "Epoch 553/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0260\n",
      "Epoch 554/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0257\n",
      "Epoch 555/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0254\n",
      "Epoch 556/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0251\n",
      "Epoch 557/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0248\n",
      "Epoch 558/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0246\n",
      "Epoch 559/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0243\n",
      "Epoch 560/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0240\n",
      "Epoch 561/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0237\n",
      "Epoch 562/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0234\n",
      "Epoch 563/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0232\n",
      "Epoch 564/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0229\n",
      "Epoch 565/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0226\n",
      "Epoch 566/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0223\n",
      "Epoch 567/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0221\n",
      "Epoch 568/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0218\n",
      "Epoch 569/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0215\n",
      "Epoch 570/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0213\n",
      "Epoch 571/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0210\n",
      "Epoch 572/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0208\n",
      "Epoch 573/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0205\n",
      "Epoch 574/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0202\n",
      "Epoch 575/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0200\n",
      "Epoch 576/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0197\n",
      "Epoch 577/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0195\n",
      "Epoch 578/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0192\n",
      "Epoch 579/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0190\n",
      "Epoch 580/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0187\n",
      "Epoch 581/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 582/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0183\n",
      "Epoch 583/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0180\n",
      "Epoch 584/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0178\n",
      "Epoch 585/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0175\n",
      "Epoch 586/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0173\n",
      "Epoch 587/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0171\n",
      "Epoch 588/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0168\n",
      "Epoch 589/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0166\n",
      "Epoch 590/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0164\n",
      "Epoch 591/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0162\n",
      "Epoch 592/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0159\n",
      "Epoch 593/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0157\n",
      "Epoch 594/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0155\n",
      "Epoch 595/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0153\n",
      "Epoch 596/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0151\n",
      "Epoch 597/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0149\n",
      "Epoch 598/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0146\n",
      "Epoch 599/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0144\n",
      "Epoch 600/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0142\n",
      "Epoch 601/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0140\n",
      "Epoch 602/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0138\n",
      "Epoch 603/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0136\n",
      "Epoch 604/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0134\n",
      "Epoch 605/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0132\n",
      "Epoch 606/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0130\n",
      "Epoch 607/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0128\n",
      "Epoch 608/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0126\n",
      "Epoch 609/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0124\n",
      "Epoch 610/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0123\n",
      "Epoch 611/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0121\n",
      "Epoch 612/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0119\n",
      "Epoch 613/800\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.0013 - val_loss: 0.0117\n",
      "Epoch 614/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0115\n",
      "Epoch 615/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0113\n",
      "Epoch 616/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0112\n",
      "Epoch 617/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0110\n",
      "Epoch 618/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0108\n",
      "Epoch 619/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0106\n",
      "Epoch 620/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0105\n",
      "Epoch 621/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0103\n",
      "Epoch 622/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0101\n",
      "Epoch 623/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0100\n",
      "Epoch 624/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0098\n",
      "Epoch 625/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0096\n",
      "Epoch 626/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0095\n",
      "Epoch 627/800\n",
      "5/5 [==============================] - 0s 930us/step - loss: 0.0011 - val_loss: 0.0093\n",
      "Epoch 628/800\n",
      "5/5 [==============================] - 0s 957us/step - loss: 0.0011 - val_loss: 0.0092\n",
      "Epoch 629/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0090\n",
      "Epoch 630/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 0.0089\n",
      "Epoch 631/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0087\n",
      "Epoch 632/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.9830e-04 - val_loss: 0.0086\n",
      "Epoch 633/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.8511e-04 - val_loss: 0.0084\n",
      "Epoch 634/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.7205e-04 - val_loss: 0.0083\n",
      "Epoch 635/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.5912e-04 - val_loss: 0.0081\n",
      "Epoch 636/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4631e-04 - val_loss: 0.0080\n",
      "Epoch 637/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.3363e-04 - val_loss: 0.0078\n",
      "Epoch 638/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.2107e-04 - val_loss: 0.0077\n",
      "Epoch 639/800\n",
      "5/5 [==============================] - 0s 951us/step - loss: 9.0864e-04 - val_loss: 0.0076\n",
      "Epoch 640/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.9633e-04 - val_loss: 0.0074\n",
      "Epoch 641/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.8414e-04 - val_loss: 0.0073\n",
      "Epoch 642/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.7208e-04 - val_loss: 0.0072\n",
      "Epoch 643/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6014e-04 - val_loss: 0.0070\n",
      "Epoch 644/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.4833e-04 - val_loss: 0.0069\n",
      "Epoch 645/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.3663e-04 - val_loss: 0.0068\n",
      "Epoch 646/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.2506e-04 - val_loss: 0.0066\n",
      "Epoch 647/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1361e-04 - val_loss: 0.0065\n",
      "Epoch 648/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0228e-04 - val_loss: 0.0064\n",
      "Epoch 649/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.9107e-04 - val_loss: 0.0063\n",
      "Epoch 650/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7998e-04 - val_loss: 0.0061\n",
      "Epoch 651/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.6900e-04 - val_loss: 0.0060\n",
      "Epoch 652/800\n",
      "5/5 [==============================] - 0s 911us/step - loss: 7.5815e-04 - val_loss: 0.0059\n",
      "Epoch 653/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4741e-04 - val_loss: 0.0058\n",
      "Epoch 654/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.3679e-04 - val_loss: 0.0057\n",
      "Epoch 655/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2629e-04 - val_loss: 0.0056\n",
      "Epoch 656/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.1590e-04 - val_loss: 0.0055\n",
      "Epoch 657/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.0563e-04 - val_loss: 0.0054\n",
      "Epoch 658/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.9547e-04 - val_loss: 0.0052\n",
      "Epoch 659/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8543e-04 - val_loss: 0.0051\n",
      "Epoch 660/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.7550e-04 - val_loss: 0.0050\n",
      "Epoch 661/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.6568e-04 - val_loss: 0.0049\n",
      "Epoch 662/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.5598e-04 - val_loss: 0.0048\n",
      "Epoch 663/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.4638e-04 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.3690e-04 - val_loss: 0.0046\n",
      "Epoch 665/800\n",
      "5/5 [==============================] - 0s 951us/step - loss: 6.2753e-04 - val_loss: 0.0045\n",
      "Epoch 666/800\n",
      "5/5 [==============================] - 0s 939us/step - loss: 6.1827e-04 - val_loss: 0.0044\n",
      "Epoch 667/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0911e-04 - val_loss: 0.0043\n",
      "Epoch 668/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.0007e-04 - val_loss: 0.0043\n",
      "Epoch 669/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9113e-04 - val_loss: 0.0042\n",
      "Epoch 670/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8230e-04 - val_loss: 0.0041\n",
      "Epoch 671/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.7358e-04 - val_loss: 0.0040\n",
      "Epoch 672/800\n",
      "5/5 [==============================] - 0s 986us/step - loss: 5.6496e-04 - val_loss: 0.0039\n",
      "Epoch 673/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.5644e-04 - val_loss: 0.0038\n",
      "Epoch 674/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.4803e-04 - val_loss: 0.0037\n",
      "Epoch 675/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3973e-04 - val_loss: 0.0036\n",
      "Epoch 676/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.3152e-04 - val_loss: 0.0036\n",
      "Epoch 677/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.2342e-04 - val_loss: 0.0035\n",
      "Epoch 678/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.1542e-04 - val_loss: 0.0034\n",
      "Epoch 679/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.0752e-04 - val_loss: 0.0033\n",
      "Epoch 680/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.9972e-04 - val_loss: 0.0032\n",
      "Epoch 681/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.9201e-04 - val_loss: 0.0032\n",
      "Epoch 682/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.8441e-04 - val_loss: 0.0031\n",
      "Epoch 683/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.7690e-04 - val_loss: 0.0030\n",
      "Epoch 684/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6949e-04 - val_loss: 0.0030\n",
      "Epoch 685/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6218e-04 - val_loss: 0.0029\n",
      "Epoch 686/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.5496e-04 - val_loss: 0.0028\n",
      "Epoch 687/800\n",
      "5/5 [==============================] - 0s 999us/step - loss: 4.4784e-04 - val_loss: 0.0027\n",
      "Epoch 688/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4081e-04 - val_loss: 0.0027\n",
      "Epoch 689/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.3387e-04 - val_loss: 0.0026\n",
      "Epoch 690/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2703e-04 - val_loss: 0.0026\n",
      "Epoch 691/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2027e-04 - val_loss: 0.0025\n",
      "Epoch 692/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.1361e-04 - val_loss: 0.0024\n",
      "Epoch 693/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0703e-04 - val_loss: 0.0024\n",
      "Epoch 694/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0055e-04 - val_loss: 0.0023\n",
      "Epoch 695/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9415e-04 - val_loss: 0.0022\n",
      "Epoch 696/800\n",
      "5/5 [==============================] - 0s 985us/step - loss: 3.8784e-04 - val_loss: 0.0022\n",
      "Epoch 697/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8162e-04 - val_loss: 0.0021\n",
      "Epoch 698/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7548e-04 - val_loss: 0.0021\n",
      "Epoch 699/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.6943e-04 - val_loss: 0.0020\n",
      "Epoch 700/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6346e-04 - val_loss: 0.0020\n",
      "Epoch 701/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5758e-04 - val_loss: 0.0019\n",
      "Epoch 702/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.5178e-04 - val_loss: 0.0019\n",
      "Epoch 703/800\n",
      "5/5 [==============================] - 0s 989us/step - loss: 3.4606e-04 - val_loss: 0.0018\n",
      "Epoch 704/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.4042e-04 - val_loss: 0.0018\n",
      "Epoch 705/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.3486e-04 - val_loss: 0.0017\n",
      "Epoch 706/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2939e-04 - val_loss: 0.0017\n",
      "Epoch 707/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.2398e-04 - val_loss: 0.0016\n",
      "Epoch 708/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1866e-04 - val_loss: 0.0016\n",
      "Epoch 709/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1342e-04 - val_loss: 0.0015\n",
      "Epoch 710/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.0825e-04 - val_loss: 0.0015\n",
      "Epoch 711/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.0316e-04 - val_loss: 0.0014\n",
      "Epoch 712/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9814e-04 - val_loss: 0.0014\n",
      "Epoch 713/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9320e-04 - val_loss: 0.0014\n",
      "Epoch 714/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8833e-04 - val_loss: 0.0013\n",
      "Epoch 715/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8353e-04 - val_loss: 0.0013\n",
      "Epoch 716/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7881e-04 - val_loss: 0.0012\n",
      "Epoch 717/800\n",
      "5/5 [==============================] - 0s 993us/step - loss: 2.7416e-04 - val_loss: 0.0012\n",
      "Epoch 718/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6957e-04 - val_loss: 0.0012\n",
      "Epoch 719/800\n",
      "5/5 [==============================] - 0s 920us/step - loss: 2.6506e-04 - val_loss: 0.0011\n",
      "Epoch 720/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6062e-04 - val_loss: 0.0011\n",
      "Epoch 721/800\n",
      "5/5 [==============================] - 0s 863us/step - loss: 2.5624e-04 - val_loss: 0.0011\n",
      "Epoch 722/800\n",
      "5/5 [==============================] - 0s 921us/step - loss: 2.5193e-04 - val_loss: 0.0010\n",
      "Epoch 723/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4769e-04 - val_loss: 9.8860e-04\n",
      "Epoch 724/800\n",
      "5/5 [==============================] - 0s 926us/step - loss: 2.4351e-04 - val_loss: 9.5623e-04\n",
      "Epoch 725/800\n",
      "5/5 [==============================] - 0s 896us/step - loss: 2.3940e-04 - val_loss: 9.2463e-04\n",
      "Epoch 726/800\n",
      "5/5 [==============================] - 0s 940us/step - loss: 2.3535e-04 - val_loss: 8.9376e-04\n",
      "Epoch 727/800\n",
      "5/5 [==============================] - 0s 953us/step - loss: 2.3137e-04 - val_loss: 8.6361e-04\n",
      "Epoch 728/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2745e-04 - val_loss: 8.3418e-04\n",
      "Epoch 729/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2359e-04 - val_loss: 8.0546e-04\n",
      "Epoch 730/800\n",
      "5/5 [==============================] - 0s 992us/step - loss: 2.1979e-04 - val_loss: 7.7743e-04\n",
      "Epoch 731/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1605e-04 - val_loss: 7.5010e-04\n",
      "Epoch 732/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1237e-04 - val_loss: 7.2344e-04\n",
      "Epoch 733/800\n",
      "5/5 [==============================] - 0s 810us/step - loss: 2.0876e-04 - val_loss: 6.9744e-04\n",
      "Epoch 734/800\n",
      "5/5 [==============================] - 0s 981us/step - loss: 2.0519e-04 - val_loss: 6.7210e-04\n",
      "Epoch 735/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0169e-04 - val_loss: 6.4741e-04\n",
      "Epoch 736/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9825e-04 - val_loss: 6.2335e-04\n",
      "Epoch 737/800\n",
      "5/5 [==============================] - 0s 811us/step - loss: 1.9486e-04 - val_loss: 5.9992e-04\n",
      "Epoch 738/800\n",
      "5/5 [==============================] - 0s 968us/step - loss: 1.9153e-04 - val_loss: 5.7710e-04\n",
      "Epoch 739/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8825e-04 - val_loss: 5.5488e-04\n",
      "Epoch 740/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8502e-04 - val_loss: 5.3327e-04\n",
      "Epoch 741/800\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.8185e-04 - val_loss: 5.1223e-04\n",
      "Epoch 742/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7874e-04 - val_loss: 4.9177e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 743/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7567e-04 - val_loss: 4.7188e-04\n",
      "Epoch 744/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7266e-04 - val_loss: 4.5254e-04\n",
      "Epoch 745/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6969e-04 - val_loss: 4.3376e-04\n",
      "Epoch 746/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6678e-04 - val_loss: 4.1551e-04\n",
      "Epoch 747/800\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6392e-04 - val_loss: 3.9779e-04\n",
      "Epoch 748/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6110e-04 - val_loss: 3.8058e-04\n",
      "Epoch 749/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5833e-04 - val_loss: 3.6389e-04\n",
      "Epoch 750/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5561e-04 - val_loss: 3.4771e-04\n",
      "Epoch 751/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5294e-04 - val_loss: 3.3201e-04\n",
      "Epoch 752/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5032e-04 - val_loss: 3.1680e-04\n",
      "Epoch 753/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4773e-04 - val_loss: 3.0206e-04\n",
      "Epoch 754/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4520e-04 - val_loss: 2.8779e-04\n",
      "Epoch 755/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4271e-04 - val_loss: 2.7398e-04\n",
      "Epoch 756/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4026e-04 - val_loss: 2.6062e-04\n",
      "Epoch 757/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3785e-04 - val_loss: 2.4769e-04\n",
      "Epoch 758/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3549e-04 - val_loss: 2.3521e-04\n",
      "Epoch 759/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3317e-04 - val_loss: 2.2314e-04\n",
      "Epoch 760/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3089e-04 - val_loss: 2.1149e-04\n",
      "Epoch 761/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2865e-04 - val_loss: 2.0025e-04\n",
      "Epoch 762/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2645e-04 - val_loss: 1.8942e-04\n",
      "Epoch 763/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2429e-04 - val_loss: 1.7898e-04\n",
      "Epoch 764/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2217e-04 - val_loss: 1.6892e-04\n",
      "Epoch 765/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2009e-04 - val_loss: 1.5924e-04\n",
      "Epoch 766/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1804e-04 - val_loss: 1.4993e-04\n",
      "Epoch 767/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1604e-04 - val_loss: 1.4098e-04\n",
      "Epoch 768/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1407e-04 - val_loss: 1.3239e-04\n",
      "Epoch 769/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1213e-04 - val_loss: 1.2415e-04\n",
      "Epoch 770/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1023e-04 - val_loss: 1.1625e-04\n",
      "Epoch 771/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0837e-04 - val_loss: 1.0868e-04\n",
      "Epoch 772/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0654e-04 - val_loss: 1.0144e-04\n",
      "Epoch 773/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0474e-04 - val_loss: 9.4517e-05\n",
      "Epoch 774/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0298e-04 - val_loss: 8.7910e-05\n",
      "Epoch 775/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0125e-04 - val_loss: 8.1607e-05\n",
      "Epoch 776/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.9554e-05 - val_loss: 7.5607e-05\n",
      "Epoch 777/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.7889e-05 - val_loss: 6.9899e-05\n",
      "Epoch 778/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.6255e-05 - val_loss: 6.4479e-05\n",
      "Epoch 779/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4652e-05 - val_loss: 5.9338e-05\n",
      "Epoch 780/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.3080e-05 - val_loss: 5.4471e-05\n",
      "Epoch 781/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.1537e-05 - val_loss: 4.9873e-05\n",
      "Epoch 782/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.0024e-05 - val_loss: 4.5536e-05\n",
      "Epoch 783/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.8540e-05 - val_loss: 4.1455e-05\n",
      "Epoch 784/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.7084e-05 - val_loss: 3.7624e-05\n",
      "Epoch 785/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.5656e-05 - val_loss: 3.4037e-05\n",
      "Epoch 786/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4256e-05 - val_loss: 3.0687e-05\n",
      "Epoch 787/800\n",
      "5/5 [==============================] - 0s 973us/step - loss: 8.2883e-05 - val_loss: 2.7572e-05\n",
      "Epoch 788/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1536e-05 - val_loss: 2.4681e-05\n",
      "Epoch 789/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0216e-05 - val_loss: 2.2012e-05\n",
      "Epoch 790/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.8921e-05 - val_loss: 1.9560e-05\n",
      "Epoch 791/800\n",
      "5/5 [==============================] - 0s 967us/step - loss: 7.7652e-05 - val_loss: 1.7317e-05\n",
      "Epoch 792/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.6408e-05 - val_loss: 1.5280e-05\n",
      "Epoch 793/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.5188e-05 - val_loss: 1.3443e-05\n",
      "Epoch 794/800\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.3992e-05 - val_loss: 1.1801e-05\n",
      "Epoch 795/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2820e-05 - val_loss: 1.0348e-05\n",
      "Epoch 796/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.1671e-05 - val_loss: 9.0814e-06\n",
      "Epoch 797/800\n",
      "5/5 [==============================] - 0s 912us/step - loss: 7.0545e-05 - val_loss: 7.9936e-06\n",
      "Epoch 798/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.9442e-05 - val_loss: 7.0817e-06\n",
      "Epoch 799/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8360e-05 - val_loss: 6.3402e-06\n",
      "Epoch 800/800\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.7300e-05 - val_loss: 5.7647e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c782e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "%matplotlib inline\n",
    " \n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=800, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'])\n",
    "pyplot.plot(history.history['val_loss'])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example creates a line plot showing the train and validation loss meeting.\n",
    "\n",
    "Ideally, we would like to see model performance like this if possible, although this may not be possible on challenging problems with a lot of data.\n",
    "\n",
    "## 5. Overfit Example\n",
    "An overfit model is one where performance on the train set is good and continues to improve, whereas performance on the validation set improves to a point and then begins to degrade.\n",
    "\n",
    "This can be diagnosed from a plot where the train loss slopes down and the validation loss slopes down, hits an inflection point, and starts to slope up again.\n",
    "\n",
    "The example below demonstrates an overfit LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/1200\n",
      "5/5 [==============================] - 2s 353ms/step - loss: 0.1042 - val_loss: 0.6132\n",
      "Epoch 2/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.6086\n",
      "Epoch 3/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1015 - val_loss: 0.6040\n",
      "Epoch 4/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1002 - val_loss: 0.5994\n",
      "Epoch 5/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.5948\n",
      "Epoch 6/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 0.5902\n",
      "Epoch 7/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0963 - val_loss: 0.5856\n",
      "Epoch 8/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0950 - val_loss: 0.5810\n",
      "Epoch 9/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0937 - val_loss: 0.5765\n",
      "Epoch 10/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.5720\n",
      "Epoch 11/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.5674\n",
      "Epoch 12/1200\n",
      "5/5 [==============================] - 0s 952us/step - loss: 0.0899 - val_loss: 0.5629\n",
      "Epoch 13/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.5584\n",
      "Epoch 14/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.5540\n",
      "Epoch 15/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.5495\n",
      "Epoch 16/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.5451\n",
      "Epoch 17/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.5407\n",
      "Epoch 18/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.5362\n",
      "Epoch 19/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.5319\n",
      "Epoch 20/1200\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0803 - val_loss: 0.5275\n",
      "Epoch 21/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0791 - val_loss: 0.5231\n",
      "Epoch 22/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.5188\n",
      "Epoch 23/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.5144\n",
      "Epoch 24/1200\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0757 - val_loss: 0.5101\n",
      "Epoch 25/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.5058\n",
      "Epoch 26/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.5015\n",
      "Epoch 27/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.4972\n",
      "Epoch 28/1200\n",
      "5/5 [==============================] - 0s 905us/step - loss: 0.0712 - val_loss: 0.4930\n",
      "Epoch 29/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0701 - val_loss: 0.4887\n",
      "Epoch 30/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.4845\n",
      "Epoch 31/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0680 - val_loss: 0.4802\n",
      "Epoch 32/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0669 - val_loss: 0.4760\n",
      "Epoch 33/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0658 - val_loss: 0.4718\n",
      "Epoch 34/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0648 - val_loss: 0.4676\n",
      "Epoch 35/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0638 - val_loss: 0.4634\n",
      "Epoch 36/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.4593\n",
      "Epoch 37/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0617 - val_loss: 0.4552\n",
      "Epoch 38/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0607 - val_loss: 0.4510\n",
      "Epoch 39/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.4469\n",
      "Epoch 40/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.4429\n",
      "Epoch 41/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.4388\n",
      "Epoch 42/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.4347\n",
      "Epoch 43/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.4307\n",
      "Epoch 44/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.4266\n",
      "Epoch 45/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.4226\n",
      "Epoch 46/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.4186\n",
      "Epoch 47/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0521 - val_loss: 0.4146\n",
      "Epoch 48/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.4107\n",
      "Epoch 49/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.4067\n",
      "Epoch 50/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.4028\n",
      "Epoch 51/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.3989\n",
      "Epoch 52/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.3950\n",
      "Epoch 53/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0469 - val_loss: 0.3911\n",
      "Epoch 54/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.3872\n",
      "Epoch 55/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.3834\n",
      "Epoch 56/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0444 - val_loss: 0.3795\n",
      "Epoch 57/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.3757\n",
      "Epoch 58/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.3719\n",
      "Epoch 59/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.3682\n",
      "Epoch 60/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.3644\n",
      "Epoch 61/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.3607\n",
      "Epoch 62/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.3570\n",
      "Epoch 63/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.3533\n",
      "Epoch 64/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.3496\n",
      "Epoch 65/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0374 - val_loss: 0.3460\n",
      "Epoch 66/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.3423\n",
      "Epoch 67/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.3387\n",
      "Epoch 68/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.3351\n",
      "Epoch 69/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0346 - val_loss: 0.3316\n",
      "Epoch 70/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.3280\n",
      "Epoch 71/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0333 - val_loss: 0.3245\n",
      "Epoch 72/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.3210\n",
      "Epoch 73/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.3175\n",
      "Epoch 74/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.3141\n",
      "Epoch 75/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.3107\n",
      "Epoch 76/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.3073\n",
      "Epoch 77/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0296 - val_loss: 0.3039\n",
      "Epoch 78/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.3006\n",
      "Epoch 79/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0284 - val_loss: 0.2972\n",
      "Epoch 80/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0278 - val_loss: 0.2939\n",
      "Epoch 81/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.2907\n",
      "Epoch 82/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.2874\n",
      "Epoch 83/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.2842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.2810\n",
      "Epoch 85/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.2779\n",
      "Epoch 86/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.2747\n",
      "Epoch 87/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.2716\n",
      "Epoch 88/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.2686\n",
      "Epoch 89/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.2655\n",
      "Epoch 90/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.2625\n",
      "Epoch 91/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.2595\n",
      "Epoch 92/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0219 - val_loss: 0.2566\n",
      "Epoch 93/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2536\n",
      "Epoch 94/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.2507\n",
      "Epoch 95/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.2479\n",
      "Epoch 96/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.2450\n",
      "Epoch 97/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.2422\n",
      "Epoch 98/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2395\n",
      "Epoch 99/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.2367\n",
      "Epoch 100/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.2340\n",
      "Epoch 101/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.2313\n",
      "Epoch 102/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.2287\n",
      "Epoch 103/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.2261\n",
      "Epoch 104/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.2235\n",
      "Epoch 105/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2210\n",
      "Epoch 106/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2184\n",
      "Epoch 107/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.2160\n",
      "Epoch 108/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.2135\n",
      "Epoch 109/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2111\n",
      "Epoch 110/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.2087\n",
      "Epoch 111/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2064\n",
      "Epoch 112/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2040\n",
      "Epoch 113/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2018\n",
      "Epoch 114/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.1995\n",
      "Epoch 115/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1973\n",
      "Epoch 116/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0143 - val_loss: 0.1951\n",
      "Epoch 117/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1930\n",
      "Epoch 118/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1909\n",
      "Epoch 119/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1888\n",
      "Epoch 120/1200\n",
      "5/5 [==============================] - 0s 937us/step - loss: 0.0135 - val_loss: 0.1867\n",
      "Epoch 121/1200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0133 - val_loss: 0.1847\n",
      "Epoch 122/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1827\n",
      "Epoch 123/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1808\n",
      "Epoch 124/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1789\n",
      "Epoch 125/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1770\n",
      "Epoch 126/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1751\n",
      "Epoch 127/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1733\n",
      "Epoch 128/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1715\n",
      "Epoch 129/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1698\n",
      "Epoch 130/1200\n",
      "5/5 [==============================] - 0s 977us/step - loss: 0.0120 - val_loss: 0.1681\n",
      "Epoch 131/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1664\n",
      "Epoch 132/1200\n",
      "5/5 [==============================] - 0s 923us/step - loss: 0.0117 - val_loss: 0.1647\n",
      "Epoch 133/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1631\n",
      "Epoch 134/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1615\n",
      "Epoch 135/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1599\n",
      "Epoch 136/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1584\n",
      "Epoch 137/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1569\n",
      "Epoch 138/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1554\n",
      "Epoch 139/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1540\n",
      "Epoch 140/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1526\n",
      "Epoch 141/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1512\n",
      "Epoch 142/1200\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0108 - val_loss: 0.1498\n",
      "Epoch 143/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1485\n",
      "Epoch 144/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1472\n",
      "Epoch 145/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1459\n",
      "Epoch 146/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1447\n",
      "Epoch 147/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1435\n",
      "Epoch 148/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1423\n",
      "Epoch 149/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1411\n",
      "Epoch 150/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1400\n",
      "Epoch 151/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1388\n",
      "Epoch 152/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1378\n",
      "Epoch 153/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1367\n",
      "Epoch 154/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1356\n",
      "Epoch 155/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1346\n",
      "Epoch 156/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1336\n",
      "Epoch 157/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1326\n",
      "Epoch 158/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1317\n",
      "Epoch 159/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1308\n",
      "Epoch 160/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1298\n",
      "Epoch 161/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1290\n",
      "Epoch 162/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1281\n",
      "Epoch 163/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1272\n",
      "Epoch 164/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1264\n",
      "Epoch 165/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1248\n",
      "Epoch 167/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1240\n",
      "Epoch 168/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1232\n",
      "Epoch 169/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1225\n",
      "Epoch 170/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1218\n",
      "Epoch 171/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1211\n",
      "Epoch 172/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1204\n",
      "Epoch 173/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1197\n",
      "Epoch 174/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1190\n",
      "Epoch 175/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1184\n",
      "Epoch 176/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1177\n",
      "Epoch 177/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1171\n",
      "Epoch 178/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1165\n",
      "Epoch 179/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1159\n",
      "Epoch 180/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1153\n",
      "Epoch 181/1200\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0092 - val_loss: 0.1147\n",
      "Epoch 182/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1141\n",
      "Epoch 183/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1136\n",
      "Epoch 184/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1130\n",
      "Epoch 185/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1125\n",
      "Epoch 186/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1120\n",
      "Epoch 187/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1115\n",
      "Epoch 188/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1110\n",
      "Epoch 189/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1105\n",
      "Epoch 190/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1100\n",
      "Epoch 191/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1095\n",
      "Epoch 192/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1090\n",
      "Epoch 193/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1085\n",
      "Epoch 194/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1081\n",
      "Epoch 195/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1076\n",
      "Epoch 196/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1072\n",
      "Epoch 197/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1067\n",
      "Epoch 198/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1063\n",
      "Epoch 199/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1059\n",
      "Epoch 200/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1054\n",
      "Epoch 201/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1050\n",
      "Epoch 202/1200\n",
      "5/5 [==============================] - 0s 967us/step - loss: 0.0086 - val_loss: 0.1046\n",
      "Epoch 203/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1042\n",
      "Epoch 204/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1038\n",
      "Epoch 205/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1034\n",
      "Epoch 206/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1030\n",
      "Epoch 207/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1026\n",
      "Epoch 208/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1022\n",
      "Epoch 209/1200\n",
      "5/5 [==============================] - 0s 930us/step - loss: 0.0085 - val_loss: 0.1018\n",
      "Epoch 210/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1014\n",
      "Epoch 211/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1010\n",
      "Epoch 212/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1007\n",
      "Epoch 213/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1003\n",
      "Epoch 214/1200\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0083 - val_loss: 0.0999\n",
      "Epoch 215/1200\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0083 - val_loss: 0.0995\n",
      "Epoch 216/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0992\n",
      "Epoch 217/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0988\n",
      "Epoch 218/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0984\n",
      "Epoch 219/1200\n",
      "5/5 [==============================] - 0s 934us/step - loss: 0.0082 - val_loss: 0.0981\n",
      "Epoch 220/1200\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0082 - val_loss: 0.0977\n",
      "Epoch 221/1200\n",
      "5/5 [==============================] - 0s 878us/step - loss: 0.0082 - val_loss: 0.0973\n",
      "Epoch 222/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0970\n",
      "Epoch 223/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0966\n",
      "Epoch 224/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0962\n",
      "Epoch 225/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0959\n",
      "Epoch 226/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0955\n",
      "Epoch 227/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0952\n",
      "Epoch 228/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0948\n",
      "Epoch 229/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0945\n",
      "Epoch 230/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0941\n",
      "Epoch 231/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0937\n",
      "Epoch 232/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0934\n",
      "Epoch 233/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0930\n",
      "Epoch 234/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0927\n",
      "Epoch 235/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0923\n",
      "Epoch 236/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0920\n",
      "Epoch 237/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0916\n",
      "Epoch 238/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0913\n",
      "Epoch 239/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0909\n",
      "Epoch 240/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0906\n",
      "Epoch 241/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0902\n",
      "Epoch 242/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0899\n",
      "Epoch 243/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0895\n",
      "Epoch 244/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0891\n",
      "Epoch 245/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0888\n",
      "Epoch 246/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0884\n",
      "Epoch 247/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0877\n",
      "Epoch 249/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0874\n",
      "Epoch 250/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0870\n",
      "Epoch 251/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0867\n",
      "Epoch 252/1200\n",
      "5/5 [==============================] - 0s 971us/step - loss: 0.0074 - val_loss: 0.0863\n",
      "Epoch 253/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0860\n",
      "Epoch 254/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0856\n",
      "Epoch 255/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0853\n",
      "Epoch 256/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0849\n",
      "Epoch 257/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0846\n",
      "Epoch 258/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0842\n",
      "Epoch 259/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0838\n",
      "Epoch 260/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0835\n",
      "Epoch 261/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0831\n",
      "Epoch 262/1200\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0071 - val_loss: 0.0828\n",
      "Epoch 263/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0071 - val_loss: 0.0824\n",
      "Epoch 264/1200\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0070 - val_loss: 0.0821\n",
      "Epoch 265/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0817\n",
      "Epoch 266/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0813\n",
      "Epoch 267/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 0.0810\n",
      "Epoch 268/1200\n",
      "5/5 [==============================] - 0s 946us/step - loss: 0.0069 - val_loss: 0.0806\n",
      "Epoch 269/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0803\n",
      "Epoch 270/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 0.0799\n",
      "Epoch 271/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0796\n",
      "Epoch 272/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0792\n",
      "Epoch 273/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0788\n",
      "Epoch 274/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0785\n",
      "Epoch 275/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 0.0781\n",
      "Epoch 276/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0778\n",
      "Epoch 277/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0774\n",
      "Epoch 278/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 0.0771\n",
      "Epoch 279/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0767\n",
      "Epoch 280/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0763\n",
      "Epoch 281/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 0.0760\n",
      "Epoch 282/1200\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0066 - val_loss: 0.0756\n",
      "Epoch 283/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0753\n",
      "Epoch 284/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0749\n",
      "Epoch 285/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0745\n",
      "Epoch 286/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 0.0742\n",
      "Epoch 287/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0738\n",
      "Epoch 288/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0735\n",
      "Epoch 289/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0731\n",
      "Epoch 290/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 0.0727\n",
      "Epoch 291/1200\n",
      "5/5 [==============================] - 0s 895us/step - loss: 0.0063 - val_loss: 0.0724\n",
      "Epoch 292/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0720\n",
      "Epoch 293/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0717\n",
      "Epoch 294/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0713\n",
      "Epoch 295/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0709\n",
      "Epoch 296/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0706\n",
      "Epoch 297/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 0.0702\n",
      "Epoch 298/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0699\n",
      "Epoch 299/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0695\n",
      "Epoch 300/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 0.0691\n",
      "Epoch 301/1200\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0061 - val_loss: 0.0688\n",
      "Epoch 302/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0684\n",
      "Epoch 303/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0681\n",
      "Epoch 304/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 0.0677\n",
      "Epoch 305/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0674\n",
      "Epoch 306/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0670\n",
      "Epoch 307/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0666\n",
      "Epoch 308/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 0.0663\n",
      "Epoch 309/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0659\n",
      "Epoch 310/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0656\n",
      "Epoch 311/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0652\n",
      "Epoch 312/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 0.0648\n",
      "Epoch 313/1200\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0057 - val_loss: 0.0645\n",
      "Epoch 314/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0641\n",
      "Epoch 315/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0638\n",
      "Epoch 316/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 0.0634\n",
      "Epoch 317/1200\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.0056 - val_loss: 0.0631\n",
      "Epoch 318/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0627\n",
      "Epoch 319/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 0.0623\n",
      "Epoch 320/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0620\n",
      "Epoch 321/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0616\n",
      "Epoch 322/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0613\n",
      "Epoch 323/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 0.0609\n",
      "Epoch 324/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0606\n",
      "Epoch 325/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0602\n",
      "Epoch 326/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 0.0599\n",
      "Epoch 327/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0595\n",
      "Epoch 328/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0591\n",
      "Epoch 329/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 0.0584\n",
      "Epoch 331/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0581\n",
      "Epoch 332/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0577\n",
      "Epoch 333/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0574\n",
      "Epoch 334/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 0.0570\n",
      "Epoch 335/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0567\n",
      "Epoch 336/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0563\n",
      "Epoch 337/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0560\n",
      "Epoch 338/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 0.0556\n",
      "Epoch 339/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0553\n",
      "Epoch 340/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0549\n",
      "Epoch 341/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0546\n",
      "Epoch 342/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 0.0542\n",
      "Epoch 343/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0539\n",
      "Epoch 344/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 0.0535\n",
      "Epoch 345/1200\n",
      "5/5 [==============================] - 0s 956us/step - loss: 0.0049 - val_loss: 0.0532\n",
      "Epoch 346/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0528\n",
      "Epoch 347/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0525\n",
      "Epoch 348/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0521\n",
      "Epoch 349/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 0.0518\n",
      "Epoch 350/1200\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0047 - val_loss: 0.0514\n",
      "Epoch 351/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0511\n",
      "Epoch 352/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 0.0508\n",
      "Epoch 353/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0504\n",
      "Epoch 354/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0501\n",
      "Epoch 355/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0497\n",
      "Epoch 356/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0046 - val_loss: 0.0494\n",
      "Epoch 357/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0490\n",
      "Epoch 358/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0487\n",
      "Epoch 359/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0484\n",
      "Epoch 360/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0045 - val_loss: 0.0480\n",
      "Epoch 361/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0477\n",
      "Epoch 362/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0473\n",
      "Epoch 363/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0044 - val_loss: 0.0470\n",
      "Epoch 364/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0044 - val_loss: 0.0467\n",
      "Epoch 365/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0463\n",
      "Epoch 366/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0043 - val_loss: 0.0460\n",
      "Epoch 367/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0456\n",
      "Epoch 368/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0453\n",
      "Epoch 369/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0450\n",
      "Epoch 370/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0446\n",
      "Epoch 371/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0443\n",
      "Epoch 372/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0440\n",
      "Epoch 373/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0436\n",
      "Epoch 374/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0433\n",
      "Epoch 375/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0430\n",
      "Epoch 376/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0426\n",
      "Epoch 377/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0423\n",
      "Epoch 378/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0420\n",
      "Epoch 379/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0040 - val_loss: 0.0417\n",
      "Epoch 380/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0413\n",
      "Epoch 381/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0410\n",
      "Epoch 382/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0039 - val_loss: 0.0407\n",
      "Epoch 383/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0403\n",
      "Epoch 384/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0400\n",
      "Epoch 385/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0397\n",
      "Epoch 386/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0038 - val_loss: 0.0394\n",
      "Epoch 387/1200\n",
      "5/5 [==============================] - 0s 908us/step - loss: 0.0038 - val_loss: 0.0391\n",
      "Epoch 388/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0387\n",
      "Epoch 389/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0384\n",
      "Epoch 390/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0381\n",
      "Epoch 391/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0037 - val_loss: 0.0378\n",
      "Epoch 392/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0375\n",
      "Epoch 393/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0371\n",
      "Epoch 394/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0368\n",
      "Epoch 395/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0036 - val_loss: 0.0365\n",
      "Epoch 396/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0362\n",
      "Epoch 397/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0359\n",
      "Epoch 398/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0356\n",
      "Epoch 399/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0035 - val_loss: 0.0353\n",
      "Epoch 400/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0349\n",
      "Epoch 401/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0346\n",
      "Epoch 402/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0034 - val_loss: 0.0343\n",
      "Epoch 403/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0340\n",
      "Epoch 404/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0337\n",
      "Epoch 405/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0334\n",
      "Epoch 406/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0331\n",
      "Epoch 407/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0033 - val_loss: 0.0328\n",
      "Epoch 408/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0325\n",
      "Epoch 409/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0322\n",
      "Epoch 410/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0319\n",
      "Epoch 411/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0032 - val_loss: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0313\n",
      "Epoch 413/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0310\n",
      "Epoch 414/1200\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0031 - val_loss: 0.0307\n",
      "Epoch 415/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0031 - val_loss: 0.0304\n",
      "Epoch 416/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0301\n",
      "Epoch 417/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0298\n",
      "Epoch 418/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0295\n",
      "Epoch 419/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0030 - val_loss: 0.0292\n",
      "Epoch 420/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0289\n",
      "Epoch 421/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0286\n",
      "Epoch 422/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0284\n",
      "Epoch 423/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0281\n",
      "Epoch 424/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0029 - val_loss: 0.0278\n",
      "Epoch 425/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0275\n",
      "Epoch 426/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0272\n",
      "Epoch 427/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0269\n",
      "Epoch 428/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0028 - val_loss: 0.0267\n",
      "Epoch 429/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0264\n",
      "Epoch 430/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0261\n",
      "Epoch 431/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0258\n",
      "Epoch 432/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0027 - val_loss: 0.0256\n",
      "Epoch 433/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0253\n",
      "Epoch 434/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0250\n",
      "Epoch 435/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0026 - val_loss: 0.0247\n",
      "Epoch 436/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0245\n",
      "Epoch 437/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0242\n",
      "Epoch 438/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0239\n",
      "Epoch 439/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0237\n",
      "Epoch 440/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0234\n",
      "Epoch 441/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0025 - val_loss: 0.0231\n",
      "Epoch 442/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0229\n",
      "Epoch 443/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0226\n",
      "Epoch 444/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0224\n",
      "Epoch 445/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0221\n",
      "Epoch 446/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0024 - val_loss: 0.0218\n",
      "Epoch 447/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0216\n",
      "Epoch 448/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0213\n",
      "Epoch 449/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0211\n",
      "Epoch 450/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0023 - val_loss: 0.0208\n",
      "Epoch 451/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0206\n",
      "Epoch 452/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0203\n",
      "Epoch 453/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0201\n",
      "Epoch 454/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0198\n",
      "Epoch 455/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0022 - val_loss: 0.0196\n",
      "Epoch 456/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0194\n",
      "Epoch 457/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0191\n",
      "Epoch 458/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0189\n",
      "Epoch 459/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0186\n",
      "Epoch 460/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0021 - val_loss: 0.0184\n",
      "Epoch 461/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0182\n",
      "Epoch 462/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0179\n",
      "Epoch 463/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0177\n",
      "Epoch 464/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0175\n",
      "Epoch 465/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0020 - val_loss: 0.0172\n",
      "Epoch 466/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0170\n",
      "Epoch 467/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0168\n",
      "Epoch 468/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0166\n",
      "Epoch 469/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0163\n",
      "Epoch 470/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0019 - val_loss: 0.0161\n",
      "Epoch 471/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0159\n",
      "Epoch 472/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0157\n",
      "Epoch 473/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0155\n",
      "Epoch 474/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0153\n",
      "Epoch 475/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0151\n",
      "Epoch 476/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0018 - val_loss: 0.0148\n",
      "Epoch 477/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0146\n",
      "Epoch 478/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0144\n",
      "Epoch 479/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0142\n",
      "Epoch 480/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0017 - val_loss: 0.0140\n",
      "Epoch 481/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0138\n",
      "Epoch 482/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0136\n",
      "Epoch 483/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0134\n",
      "Epoch 484/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0132\n",
      "Epoch 485/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0130\n",
      "Epoch 486/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0128\n",
      "Epoch 487/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0016 - val_loss: 0.0126\n",
      "Epoch 488/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0124\n",
      "Epoch 489/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0122\n",
      "Epoch 490/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0121\n",
      "Epoch 491/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0119\n",
      "Epoch 492/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0117\n",
      "Epoch 493/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0015 - val_loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0113\n",
      "Epoch 495/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0111\n",
      "Epoch 496/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0110\n",
      "Epoch 497/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0108\n",
      "Epoch 498/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0106\n",
      "Epoch 499/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0014 - val_loss: 0.0104\n",
      "Epoch 500/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0103\n",
      "Epoch 501/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0101\n",
      "Epoch 502/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0099\n",
      "Epoch 503/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0098\n",
      "Epoch 504/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0096\n",
      "Epoch 505/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0013 - val_loss: 0.0094\n",
      "Epoch 506/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 507/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 508/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 509/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0088\n",
      "Epoch 510/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0086\n",
      "Epoch 511/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0085\n",
      "Epoch 512/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0012 - val_loss: 0.0083\n",
      "Epoch 513/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0082\n",
      "Epoch 514/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 515/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0079\n",
      "Epoch 516/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0077\n",
      "Epoch 517/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 518/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0075\n",
      "Epoch 519/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0011 - val_loss: 0.0073\n",
      "Epoch 520/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0072\n",
      "Epoch 521/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 522/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0010 - val_loss: 0.0069\n",
      "Epoch 523/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.0068\n",
      "Epoch 524/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.9242e-04 - val_loss: 0.0066\n",
      "Epoch 525/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.7944e-04 - val_loss: 0.0065\n",
      "Epoch 526/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.6659e-04 - val_loss: 0.0064\n",
      "Epoch 527/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.5385e-04 - val_loss: 0.0063\n",
      "Epoch 528/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.4123e-04 - val_loss: 0.0061\n",
      "Epoch 529/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.2872e-04 - val_loss: 0.0060\n",
      "Epoch 530/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.1633e-04 - val_loss: 0.0059\n",
      "Epoch 531/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.0406e-04 - val_loss: 0.0058\n",
      "Epoch 532/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.9190e-04 - val_loss: 0.0056\n",
      "Epoch 533/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.7985e-04 - val_loss: 0.0055\n",
      "Epoch 534/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.6792e-04 - val_loss: 0.0054\n",
      "Epoch 535/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.5610e-04 - val_loss: 0.0053\n",
      "Epoch 536/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.4440e-04 - val_loss: 0.0052\n",
      "Epoch 537/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.3281e-04 - val_loss: 0.0051\n",
      "Epoch 538/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.2132e-04 - val_loss: 0.0050\n",
      "Epoch 539/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0996e-04 - val_loss: 0.0049\n",
      "Epoch 540/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.9871e-04 - val_loss: 0.0047\n",
      "Epoch 541/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.8758e-04 - val_loss: 0.0046\n",
      "Epoch 542/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7655e-04 - val_loss: 0.0045\n",
      "Epoch 543/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.6564e-04 - val_loss: 0.0044\n",
      "Epoch 544/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.5484e-04 - val_loss: 0.0043\n",
      "Epoch 545/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4415e-04 - val_loss: 0.0042\n",
      "Epoch 546/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.3357e-04 - val_loss: 0.0041\n",
      "Epoch 547/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.2310e-04 - val_loss: 0.0040\n",
      "Epoch 548/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.1275e-04 - val_loss: 0.0039\n",
      "Epoch 549/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.0250e-04 - val_loss: 0.0038\n",
      "Epoch 550/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.9236e-04 - val_loss: 0.0038\n",
      "Epoch 551/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8233e-04 - val_loss: 0.0037\n",
      "Epoch 552/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.7241e-04 - val_loss: 0.0036\n",
      "Epoch 553/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.6260e-04 - val_loss: 0.0035\n",
      "Epoch 554/1200\n",
      "5/5 [==============================] - 0s 971us/step - loss: 6.5289e-04 - val_loss: 0.0034\n",
      "Epoch 555/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.4329e-04 - val_loss: 0.0033\n",
      "Epoch 556/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.3379e-04 - val_loss: 0.0032\n",
      "Epoch 557/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.2441e-04 - val_loss: 0.0031\n",
      "Epoch 558/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.1512e-04 - val_loss: 0.0031\n",
      "Epoch 559/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0595e-04 - val_loss: 0.0030\n",
      "Epoch 560/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9688e-04 - val_loss: 0.0029\n",
      "Epoch 561/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.8791e-04 - val_loss: 0.0028\n",
      "Epoch 562/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.7904e-04 - val_loss: 0.0028\n",
      "Epoch 563/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.7028e-04 - val_loss: 0.0027\n",
      "Epoch 564/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6162e-04 - val_loss: 0.0026\n",
      "Epoch 565/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.5306e-04 - val_loss: 0.0025\n",
      "Epoch 566/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.4460e-04 - val_loss: 0.0025\n",
      "Epoch 567/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3624e-04 - val_loss: 0.0024\n",
      "Epoch 568/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.2798e-04 - val_loss: 0.0023\n",
      "Epoch 569/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.1983e-04 - val_loss: 0.0023\n",
      "Epoch 570/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.1177e-04 - val_loss: 0.0022\n",
      "Epoch 571/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.0381e-04 - val_loss: 0.0021\n",
      "Epoch 572/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.9595e-04 - val_loss: 0.0021\n",
      "Epoch 573/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.8818e-04 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 574/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.8051e-04 - val_loss: 0.0019\n",
      "Epoch 575/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.7294e-04 - val_loss: 0.0019\n",
      "Epoch 576/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6546e-04 - val_loss: 0.0018\n",
      "Epoch 577/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.5808e-04 - val_loss: 0.0018\n",
      "Epoch 578/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.5079e-04 - val_loss: 0.0017\n",
      "Epoch 579/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4359e-04 - val_loss: 0.0017\n",
      "Epoch 580/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.3649e-04 - val_loss: 0.0016\n",
      "Epoch 581/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2948e-04 - val_loss: 0.0016\n",
      "Epoch 582/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2256e-04 - val_loss: 0.0015\n",
      "Epoch 583/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.1573e-04 - val_loss: 0.0015\n",
      "Epoch 584/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0899e-04 - val_loss: 0.0014\n",
      "Epoch 585/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0234e-04 - val_loss: 0.0014\n",
      "Epoch 586/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9578e-04 - val_loss: 0.0013\n",
      "Epoch 587/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8930e-04 - val_loss: 0.0013\n",
      "Epoch 588/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8291e-04 - val_loss: 0.0012\n",
      "Epoch 589/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7661e-04 - val_loss: 0.0012\n",
      "Epoch 590/1200\n",
      "5/5 [==============================] - 0s 923us/step - loss: 3.7039e-04 - val_loss: 0.0011\n",
      "Epoch 591/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6426e-04 - val_loss: 0.0011\n",
      "Epoch 592/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5822e-04 - val_loss: 0.0011\n",
      "Epoch 593/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5226e-04 - val_loss: 0.0010\n",
      "Epoch 594/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4638e-04 - val_loss: 9.7746e-04\n",
      "Epoch 595/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4058e-04 - val_loss: 9.3978e-04\n",
      "Epoch 596/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3486e-04 - val_loss: 9.0306e-04\n",
      "Epoch 597/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2923e-04 - val_loss: 8.6729e-04\n",
      "Epoch 598/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2368e-04 - val_loss: 8.3245e-04\n",
      "Epoch 599/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.1820e-04 - val_loss: 7.9854e-04\n",
      "Epoch 600/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 3.1280e-04 - val_loss: 7.6553e-04\n",
      "Epoch 601/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0749e-04 - val_loss: 7.3340e-04\n",
      "Epoch 602/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0224e-04 - val_loss: 7.0218e-04\n",
      "Epoch 603/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9708e-04 - val_loss: 6.7183e-04\n",
      "Epoch 604/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9199e-04 - val_loss: 6.4235e-04\n",
      "Epoch 605/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8697e-04 - val_loss: 6.1371e-04\n",
      "Epoch 606/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.8203e-04 - val_loss: 5.8592e-04\n",
      "Epoch 607/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7717e-04 - val_loss: 5.5895e-04\n",
      "Epoch 608/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7237e-04 - val_loss: 5.3280e-04\n",
      "Epoch 609/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6765e-04 - val_loss: 5.0746e-04\n",
      "Epoch 610/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6300e-04 - val_loss: 4.8292e-04\n",
      "Epoch 611/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5842e-04 - val_loss: 4.5916e-04\n",
      "Epoch 612/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5391e-04 - val_loss: 4.3616e-04\n",
      "Epoch 613/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4947e-04 - val_loss: 4.1392e-04\n",
      "Epoch 614/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4510e-04 - val_loss: 3.9243e-04\n",
      "Epoch 615/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4079e-04 - val_loss: 3.7169e-04\n",
      "Epoch 616/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3656e-04 - val_loss: 3.5167e-04\n",
      "Epoch 617/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3239e-04 - val_loss: 3.3236e-04\n",
      "Epoch 618/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2828e-04 - val_loss: 3.1376e-04\n",
      "Epoch 619/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2424e-04 - val_loss: 2.9585e-04\n",
      "Epoch 620/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2026e-04 - val_loss: 2.7861e-04\n",
      "Epoch 621/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1635e-04 - val_loss: 2.6206e-04\n",
      "Epoch 622/1200\n",
      "5/5 [==============================] - 0s 918us/step - loss: 2.1250e-04 - val_loss: 2.4616e-04\n",
      "Epoch 623/1200\n",
      "5/5 [==============================] - 0s 987us/step - loss: 2.0871e-04 - val_loss: 2.3090e-04\n",
      "Epoch 624/1200\n",
      "5/5 [==============================] - 0s 983us/step - loss: 2.0498e-04 - val_loss: 2.1629e-04\n",
      "Epoch 625/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0131e-04 - val_loss: 2.0230e-04\n",
      "Epoch 626/1200\n",
      "5/5 [==============================] - 0s 977us/step - loss: 1.9771e-04 - val_loss: 1.8893e-04\n",
      "Epoch 627/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9416e-04 - val_loss: 1.7617e-04\n",
      "Epoch 628/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9067e-04 - val_loss: 1.6400e-04\n",
      "Epoch 629/1200\n",
      "5/5 [==============================] - 0s 947us/step - loss: 1.8724e-04 - val_loss: 1.5241e-04\n",
      "Epoch 630/1200\n",
      "5/5 [==============================] - 0s 928us/step - loss: 1.8387e-04 - val_loss: 1.4140e-04\n",
      "Epoch 631/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8055e-04 - val_loss: 1.3095e-04\n",
      "Epoch 632/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7728e-04 - val_loss: 1.2105e-04\n",
      "Epoch 633/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7408e-04 - val_loss: 1.1170e-04\n",
      "Epoch 634/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7092e-04 - val_loss: 1.0287e-04\n",
      "Epoch 635/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6782e-04 - val_loss: 9.4576e-05\n",
      "Epoch 636/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6478e-04 - val_loss: 8.6789e-05\n",
      "Epoch 637/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6178e-04 - val_loss: 7.9504e-05\n",
      "Epoch 638/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5884e-04 - val_loss: 7.2713e-05\n",
      "Epoch 639/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5595e-04 - val_loss: 6.6404e-05\n",
      "Epoch 640/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5310e-04 - val_loss: 6.0568e-05\n",
      "Epoch 641/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5031e-04 - val_loss: 5.5196e-05\n",
      "Epoch 642/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4757e-04 - val_loss: 5.0278e-05\n",
      "Epoch 643/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4487e-04 - val_loss: 4.5805e-05\n",
      "Epoch 644/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4223e-04 - val_loss: 4.1767e-05\n",
      "Epoch 645/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3962e-04 - val_loss: 3.8155e-05\n",
      "Epoch 646/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3707e-04 - val_loss: 3.4959e-05\n",
      "Epoch 647/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3456e-04 - val_loss: 3.2171e-05\n",
      "Epoch 648/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.3210e-04 - val_loss: 2.9782e-05\n",
      "Epoch 649/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2968e-04 - val_loss: 2.7784e-05\n",
      "Epoch 650/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2730e-04 - val_loss: 2.6166e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/1200\n",
      "5/5 [==============================] - 0s 992us/step - loss: 1.2497e-04 - val_loss: 2.4920e-05\n",
      "Epoch 652/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2268e-04 - val_loss: 2.4038e-05\n",
      "Epoch 653/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.2043e-04 - val_loss: 2.3512e-05\n",
      "Epoch 654/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1822e-04 - val_loss: 2.3332e-05\n",
      "Epoch 655/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1606e-04 - val_loss: 2.3491e-05\n",
      "Epoch 656/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.1393e-04 - val_loss: 2.3979e-05\n",
      "Epoch 657/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1185e-04 - val_loss: 2.4790e-05\n",
      "Epoch 658/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0980e-04 - val_loss: 2.5916e-05\n",
      "Epoch 659/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0779e-04 - val_loss: 2.7347e-05\n",
      "Epoch 660/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0582e-04 - val_loss: 2.9077e-05\n",
      "Epoch 661/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0388e-04 - val_loss: 3.1097e-05\n",
      "Epoch 662/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0198e-04 - val_loss: 3.3400e-05\n",
      "Epoch 663/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0012e-04 - val_loss: 3.5979e-05\n",
      "Epoch 664/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.8297e-05 - val_loss: 3.8826e-05\n",
      "Epoch 665/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.6506e-05 - val_loss: 4.1932e-05\n",
      "Epoch 666/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.4749e-05 - val_loss: 4.5292e-05\n",
      "Epoch 667/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9.3026e-05 - val_loss: 4.8898e-05\n",
      "Epoch 668/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.1337e-05 - val_loss: 5.2744e-05\n",
      "Epoch 669/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.9680e-05 - val_loss: 5.6822e-05\n",
      "Epoch 670/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.8056e-05 - val_loss: 6.1124e-05\n",
      "Epoch 671/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.6464e-05 - val_loss: 6.5646e-05\n",
      "Epoch 672/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.4903e-05 - val_loss: 7.0379e-05\n",
      "Epoch 673/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.3372e-05 - val_loss: 7.5317e-05\n",
      "Epoch 674/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.1872e-05 - val_loss: 8.0454e-05\n",
      "Epoch 675/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 8.0402e-05 - val_loss: 8.5784e-05\n",
      "Epoch 676/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.8961e-05 - val_loss: 9.1300e-05\n",
      "Epoch 677/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.7548e-05 - val_loss: 9.6996e-05\n",
      "Epoch 678/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.6164e-05 - val_loss: 1.0287e-04\n",
      "Epoch 679/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.4808e-05 - val_loss: 1.0890e-04\n",
      "Epoch 680/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.3480e-05 - val_loss: 1.1510e-04\n",
      "Epoch 681/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 7.2178e-05 - val_loss: 1.2146e-04\n",
      "Epoch 682/1200\n",
      "5/5 [==============================] - 0s 997us/step - loss: 7.0903e-05 - val_loss: 1.2797e-04\n",
      "Epoch 683/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.9653e-05 - val_loss: 1.3462e-04\n",
      "Epoch 684/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.8429e-05 - val_loss: 1.4141e-04\n",
      "Epoch 685/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.7231e-05 - val_loss: 1.4834e-04\n",
      "Epoch 686/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.6057e-05 - val_loss: 1.5539e-04\n",
      "Epoch 687/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.4907e-05 - val_loss: 1.6257e-04\n",
      "Epoch 688/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.3781e-05 - val_loss: 1.6987e-04\n",
      "Epoch 689/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2678e-05 - val_loss: 1.7728e-04\n",
      "Epoch 690/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.1598e-05 - val_loss: 1.8480e-04\n",
      "Epoch 691/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 6.0541e-05 - val_loss: 1.9242e-04\n",
      "Epoch 692/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.9506e-05 - val_loss: 2.0015e-04\n",
      "Epoch 693/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.8493e-05 - val_loss: 2.0796e-04\n",
      "Epoch 694/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.7501e-05 - val_loss: 2.1587e-04\n",
      "Epoch 695/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6530e-05 - val_loss: 2.2386e-04\n",
      "Epoch 696/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.5580e-05 - val_loss: 2.3193e-04\n",
      "Epoch 697/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.4651e-05 - val_loss: 2.4008e-04\n",
      "Epoch 698/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.3741e-05 - val_loss: 2.4830e-04\n",
      "Epoch 699/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.2850e-05 - val_loss: 2.5659e-04\n",
      "Epoch 700/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.1979e-05 - val_loss: 2.6495e-04\n",
      "Epoch 701/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.1126e-05 - val_loss: 2.7336e-04\n",
      "Epoch 702/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.0292e-05 - val_loss: 2.8183e-04\n",
      "Epoch 703/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.9476e-05 - val_loss: 2.9035e-04\n",
      "Epoch 704/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.8677e-05 - val_loss: 2.9893e-04\n",
      "Epoch 705/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.7897e-05 - val_loss: 3.0754e-04\n",
      "Epoch 706/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.7133e-05 - val_loss: 3.1620e-04\n",
      "Epoch 707/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.6386e-05 - val_loss: 3.2489e-04\n",
      "Epoch 708/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.5655e-05 - val_loss: 3.3362e-04\n",
      "Epoch 709/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.4940e-05 - val_loss: 3.4239e-04\n",
      "Epoch 710/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.4242e-05 - val_loss: 3.5118e-04\n",
      "Epoch 711/1200\n",
      "5/5 [==============================] - 0s 977us/step - loss: 4.3558e-05 - val_loss: 3.5999e-04\n",
      "Epoch 712/1200\n",
      "5/5 [==============================] - 0s 967us/step - loss: 4.2890e-05 - val_loss: 3.6883e-04\n",
      "Epoch 713/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2237e-05 - val_loss: 3.7768e-04\n",
      "Epoch 714/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.1598e-05 - val_loss: 3.8655e-04\n",
      "Epoch 715/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0974e-05 - val_loss: 3.9544e-04\n",
      "Epoch 716/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0363e-05 - val_loss: 4.0433e-04\n",
      "Epoch 717/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9767e-05 - val_loss: 4.1324e-04\n",
      "Epoch 718/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.9184e-05 - val_loss: 4.2215e-04\n",
      "Epoch 719/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8614e-05 - val_loss: 4.3105e-04\n",
      "Epoch 720/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.8057e-05 - val_loss: 4.3996e-04\n",
      "Epoch 721/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.7512e-05 - val_loss: 4.4887e-04\n",
      "Epoch 722/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6980e-05 - val_loss: 4.5776e-04\n",
      "Epoch 723/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.6461e-05 - val_loss: 4.6666e-04\n",
      "Epoch 724/1200\n",
      "5/5 [==============================] - 0s 894us/step - loss: 3.5953e-05 - val_loss: 4.7554e-04\n",
      "Epoch 725/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.5457e-05 - val_loss: 4.8441e-04\n",
      "Epoch 726/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4972e-05 - val_loss: 4.9326e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 727/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4498e-05 - val_loss: 5.0210e-04\n",
      "Epoch 728/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.4036e-05 - val_loss: 5.1093e-04\n",
      "Epoch 729/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3584e-05 - val_loss: 5.1972e-04\n",
      "Epoch 730/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3143e-05 - val_loss: 5.2850e-04\n",
      "Epoch 731/1200\n",
      "5/5 [==============================] - 0s 989us/step - loss: 3.2711e-05 - val_loss: 5.3726e-04\n",
      "Epoch 732/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2290e-05 - val_loss: 5.4599e-04\n",
      "Epoch 733/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1879e-05 - val_loss: 5.5469e-04\n",
      "Epoch 734/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1478e-05 - val_loss: 5.6336e-04\n",
      "Epoch 735/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1086e-05 - val_loss: 5.7201e-04\n",
      "Epoch 736/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0703e-05 - val_loss: 5.8062e-04\n",
      "Epoch 737/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0329e-05 - val_loss: 5.8919e-04\n",
      "Epoch 738/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9964e-05 - val_loss: 5.9773e-04\n",
      "Epoch 739/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9608e-05 - val_loss: 6.0623e-04\n",
      "Epoch 740/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9260e-05 - val_loss: 6.1469e-04\n",
      "Epoch 741/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8920e-05 - val_loss: 6.2311e-04\n",
      "Epoch 742/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8589e-05 - val_loss: 6.3149e-04\n",
      "Epoch 743/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8265e-05 - val_loss: 6.3983e-04\n",
      "Epoch 744/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7950e-05 - val_loss: 6.4813e-04\n",
      "Epoch 745/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7641e-05 - val_loss: 6.5638e-04\n",
      "Epoch 746/1200\n",
      "5/5 [==============================] - 0s 921us/step - loss: 2.7341e-05 - val_loss: 6.6459e-04\n",
      "Epoch 747/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7047e-05 - val_loss: 6.7274e-04\n",
      "Epoch 748/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6761e-05 - val_loss: 6.8085e-04\n",
      "Epoch 749/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6481e-05 - val_loss: 6.8892e-04\n",
      "Epoch 750/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.6209e-05 - val_loss: 6.9693e-04\n",
      "Epoch 751/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5943e-05 - val_loss: 7.0489e-04\n",
      "Epoch 752/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5683e-05 - val_loss: 7.1280e-04\n",
      "Epoch 753/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5430e-05 - val_loss: 7.2066e-04\n",
      "Epoch 754/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.5183e-05 - val_loss: 7.2846e-04\n",
      "Epoch 755/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4942e-05 - val_loss: 7.3621e-04\n",
      "Epoch 756/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.4707e-05 - val_loss: 7.4391e-04\n",
      "Epoch 757/1200\n",
      "5/5 [==============================] - 0s 950us/step - loss: 2.4477e-05 - val_loss: 7.5155e-04\n",
      "Epoch 758/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.4254e-05 - val_loss: 7.5914e-04\n",
      "Epoch 759/1200\n",
      "5/5 [==============================] - 0s 927us/step - loss: 2.4036e-05 - val_loss: 7.6667e-04\n",
      "Epoch 760/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3823e-05 - val_loss: 7.7414e-04\n",
      "Epoch 761/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3615e-05 - val_loss: 7.8155e-04\n",
      "Epoch 762/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3413e-05 - val_loss: 7.8891e-04\n",
      "Epoch 763/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3216e-05 - val_loss: 7.9620e-04\n",
      "Epoch 764/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.3023e-05 - val_loss: 8.0344e-04\n",
      "Epoch 765/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2836e-05 - val_loss: 8.1062e-04\n",
      "Epoch 766/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2653e-05 - val_loss: 8.1774e-04\n",
      "Epoch 767/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2474e-05 - val_loss: 8.2480e-04\n",
      "Epoch 768/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2300e-05 - val_loss: 8.3180e-04\n",
      "Epoch 769/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.2131e-05 - val_loss: 8.3874e-04\n",
      "Epoch 770/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1965e-05 - val_loss: 8.4561e-04\n",
      "Epoch 771/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1804e-05 - val_loss: 8.5243e-04\n",
      "Epoch 772/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1647e-05 - val_loss: 8.5919e-04\n",
      "Epoch 773/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1494e-05 - val_loss: 8.6588e-04\n",
      "Epoch 774/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1345e-05 - val_loss: 8.7251e-04\n",
      "Epoch 775/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1199e-05 - val_loss: 8.7908e-04\n",
      "Epoch 776/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.1057e-05 - val_loss: 8.8558e-04\n",
      "Epoch 777/1200\n",
      "5/5 [==============================] - 0s 895us/step - loss: 2.0919e-05 - val_loss: 8.9203e-04\n",
      "Epoch 778/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0784e-05 - val_loss: 8.9840e-04\n",
      "Epoch 779/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0653e-05 - val_loss: 9.0472e-04\n",
      "Epoch 780/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0525e-05 - val_loss: 9.1098e-04\n",
      "Epoch 781/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0400e-05 - val_loss: 9.1718e-04\n",
      "Epoch 782/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0279e-05 - val_loss: 9.2331e-04\n",
      "Epoch 783/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0160e-05 - val_loss: 9.2937e-04\n",
      "Epoch 784/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0045e-05 - val_loss: 9.3538e-04\n",
      "Epoch 785/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9932e-05 - val_loss: 9.4132e-04\n",
      "Epoch 786/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9823e-05 - val_loss: 9.4720e-04\n",
      "Epoch 787/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9716e-05 - val_loss: 9.5302e-04\n",
      "Epoch 788/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9612e-05 - val_loss: 9.5878e-04\n",
      "Epoch 789/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9510e-05 - val_loss: 9.6447e-04\n",
      "Epoch 790/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9412e-05 - val_loss: 9.7010e-04\n",
      "Epoch 791/1200\n",
      "5/5 [==============================] - 0s 945us/step - loss: 1.9315e-05 - val_loss: 9.7567e-04\n",
      "Epoch 792/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9221e-05 - val_loss: 9.8118e-04\n",
      "Epoch 793/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9130e-05 - val_loss: 9.8663e-04\n",
      "Epoch 794/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.9041e-05 - val_loss: 9.9201e-04\n",
      "Epoch 795/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8954e-05 - val_loss: 9.9734e-04\n",
      "Epoch 796/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8870e-05 - val_loss: 0.0010\n",
      "Epoch 797/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8787e-05 - val_loss: 0.0010\n",
      "Epoch 798/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8707e-05 - val_loss: 0.0010\n",
      "Epoch 799/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8629e-05 - val_loss: 0.0010\n",
      "Epoch 800/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8553e-05 - val_loss: 0.0010\n",
      "Epoch 801/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8479e-05 - val_loss: 0.0010\n",
      "Epoch 802/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8406e-05 - val_loss: 0.0010\n",
      "Epoch 803/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8336e-05 - val_loss: 0.0010\n",
      "Epoch 804/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8267e-05 - val_loss: 0.0010\n",
      "Epoch 805/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8201e-05 - val_loss: 0.0010\n",
      "Epoch 806/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8135e-05 - val_loss: 0.0011\n",
      "Epoch 807/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.8072e-05 - val_loss: 0.0011\n",
      "Epoch 808/1200\n",
      "5/5 [==============================] - 0s 926us/step - loss: 1.8010e-05 - val_loss: 0.0011\n",
      "Epoch 809/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7950e-05 - val_loss: 0.0011\n",
      "Epoch 810/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7891e-05 - val_loss: 0.0011\n",
      "Epoch 811/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7834e-05 - val_loss: 0.0011\n",
      "Epoch 812/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7779e-05 - val_loss: 0.0011\n",
      "Epoch 813/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7724e-05 - val_loss: 0.0011\n",
      "Epoch 814/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7671e-05 - val_loss: 0.0011\n",
      "Epoch 815/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7620e-05 - val_loss: 0.0011\n",
      "Epoch 816/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7570e-05 - val_loss: 0.0011\n",
      "Epoch 817/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7521e-05 - val_loss: 0.0011\n",
      "Epoch 818/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7473e-05 - val_loss: 0.0011\n",
      "Epoch 819/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7427e-05 - val_loss: 0.0011\n",
      "Epoch 820/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7382e-05 - val_loss: 0.0011\n",
      "Epoch 821/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7338e-05 - val_loss: 0.0011\n",
      "Epoch 822/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7295e-05 - val_loss: 0.0011\n",
      "Epoch 823/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7253e-05 - val_loss: 0.0011\n",
      "Epoch 824/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.7212e-05 - val_loss: 0.0011\n",
      "Epoch 825/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7172e-05 - val_loss: 0.0011\n",
      "Epoch 826/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7134e-05 - val_loss: 0.0011\n",
      "Epoch 827/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.7096e-05 - val_loss: 0.0011\n",
      "Epoch 828/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7059e-05 - val_loss: 0.0011\n",
      "Epoch 829/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7023e-05 - val_loss: 0.0011\n",
      "Epoch 830/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6989e-05 - val_loss: 0.0011\n",
      "Epoch 831/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6954e-05 - val_loss: 0.0012\n",
      "Epoch 832/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6921e-05 - val_loss: 0.0012\n",
      "Epoch 833/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6889e-05 - val_loss: 0.0012\n",
      "Epoch 834/1200\n",
      "5/5 [==============================] - 0s 948us/step - loss: 1.6857e-05 - val_loss: 0.0012\n",
      "Epoch 835/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6827e-05 - val_loss: 0.0012\n",
      "Epoch 836/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6797e-05 - val_loss: 0.0012\n",
      "Epoch 837/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6767e-05 - val_loss: 0.0012\n",
      "Epoch 838/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6739e-05 - val_loss: 0.0012\n",
      "Epoch 839/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6711e-05 - val_loss: 0.0012\n",
      "Epoch 840/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6684e-05 - val_loss: 0.0012\n",
      "Epoch 841/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6658e-05 - val_loss: 0.0012\n",
      "Epoch 842/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6632e-05 - val_loss: 0.0012\n",
      "Epoch 843/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6607e-05 - val_loss: 0.0012\n",
      "Epoch 844/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6582e-05 - val_loss: 0.0012\n",
      "Epoch 845/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6558e-05 - val_loss: 0.0012\n",
      "Epoch 846/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6535e-05 - val_loss: 0.0012\n",
      "Epoch 847/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6512e-05 - val_loss: 0.0012\n",
      "Epoch 848/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6489e-05 - val_loss: 0.0012\n",
      "Epoch 849/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6468e-05 - val_loss: 0.0012\n",
      "Epoch 850/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6446e-05 - val_loss: 0.0012\n",
      "Epoch 851/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6426e-05 - val_loss: 0.0012\n",
      "Epoch 852/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6406e-05 - val_loss: 0.0012\n",
      "Epoch 853/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6386e-05 - val_loss: 0.0012\n",
      "Epoch 854/1200\n",
      "5/5 [==============================] - 0s 904us/step - loss: 1.6366e-05 - val_loss: 0.0012\n",
      "Epoch 855/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6348e-05 - val_loss: 0.0012\n",
      "Epoch 856/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6329e-05 - val_loss: 0.0012\n",
      "Epoch 857/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6311e-05 - val_loss: 0.0012\n",
      "Epoch 858/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6294e-05 - val_loss: 0.0012\n",
      "Epoch 859/1200\n",
      "5/5 [==============================] - 0s 990us/step - loss: 1.6276e-05 - val_loss: 0.0012\n",
      "Epoch 860/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6260e-05 - val_loss: 0.0012\n",
      "Epoch 861/1200\n",
      "5/5 [==============================] - 0s 813us/step - loss: 1.6243e-05 - val_loss: 0.0012\n",
      "Epoch 862/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6227e-05 - val_loss: 0.0012\n",
      "Epoch 863/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6212e-05 - val_loss: 0.0012\n",
      "Epoch 864/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6196e-05 - val_loss: 0.0012\n",
      "Epoch 865/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6181e-05 - val_loss: 0.0012\n",
      "Epoch 866/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6167e-05 - val_loss: 0.0012\n",
      "Epoch 867/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6152e-05 - val_loss: 0.0012\n",
      "Epoch 868/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6138e-05 - val_loss: 0.0012\n",
      "Epoch 869/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6124e-05 - val_loss: 0.0012\n",
      "Epoch 870/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6111e-05 - val_loss: 0.0012\n",
      "Epoch 871/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6098e-05 - val_loss: 0.0012\n",
      "Epoch 872/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.6085e-05 - val_loss: 0.0012\n",
      "Epoch 873/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6072e-05 - val_loss: 0.0013\n",
      "Epoch 874/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6060e-05 - val_loss: 0.0013\n",
      "Epoch 875/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6048e-05 - val_loss: 0.0013\n",
      "Epoch 876/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6036e-05 - val_loss: 0.0013\n",
      "Epoch 877/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6024e-05 - val_loss: 0.0013\n",
      "Epoch 878/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.6012e-05 - val_loss: 0.0013\n",
      "Epoch 879/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6001e-05 - val_loss: 0.0013\n",
      "Epoch 880/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5990e-05 - val_loss: 0.0013\n",
      "Epoch 881/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5980e-05 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 882/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5969e-05 - val_loss: 0.0013\n",
      "Epoch 883/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5959e-05 - val_loss: 0.0013\n",
      "Epoch 884/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5948e-05 - val_loss: 0.0013\n",
      "Epoch 885/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5938e-05 - val_loss: 0.0013\n",
      "Epoch 886/1200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5928e-05 - val_loss: 0.0013\n",
      "Epoch 887/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5919e-05 - val_loss: 0.0013\n",
      "Epoch 888/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5909e-05 - val_loss: 0.0013\n",
      "Epoch 889/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5900e-05 - val_loss: 0.0013\n",
      "Epoch 890/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5891e-05 - val_loss: 0.0013\n",
      "Epoch 891/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5882e-05 - val_loss: 0.0013\n",
      "Epoch 892/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5873e-05 - val_loss: 0.0013\n",
      "Epoch 893/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5864e-05 - val_loss: 0.0013\n",
      "Epoch 894/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5855e-05 - val_loss: 0.0013\n",
      "Epoch 895/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5847e-05 - val_loss: 0.0013\n",
      "Epoch 896/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5839e-05 - val_loss: 0.0013\n",
      "Epoch 897/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5830e-05 - val_loss: 0.0013\n",
      "Epoch 898/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5822e-05 - val_loss: 0.0013\n",
      "Epoch 899/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5814e-05 - val_loss: 0.0013\n",
      "Epoch 900/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5807e-05 - val_loss: 0.0013\n",
      "Epoch 901/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5799e-05 - val_loss: 0.0013\n",
      "Epoch 902/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5791e-05 - val_loss: 0.0013\n",
      "Epoch 903/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5784e-05 - val_loss: 0.0013\n",
      "Epoch 904/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5776e-05 - val_loss: 0.0013\n",
      "Epoch 905/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5769e-05 - val_loss: 0.0013\n",
      "Epoch 906/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5762e-05 - val_loss: 0.0013\n",
      "Epoch 907/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5755e-05 - val_loss: 0.0013\n",
      "Epoch 908/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5748e-05 - val_loss: 0.0013\n",
      "Epoch 909/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5741e-05 - val_loss: 0.0013\n",
      "Epoch 910/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5734e-05 - val_loss: 0.0013\n",
      "Epoch 911/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5727e-05 - val_loss: 0.0013\n",
      "Epoch 912/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5720e-05 - val_loss: 0.0013\n",
      "Epoch 913/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5714e-05 - val_loss: 0.0013\n",
      "Epoch 914/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5707e-05 - val_loss: 0.0013\n",
      "Epoch 915/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5701e-05 - val_loss: 0.0013\n",
      "Epoch 916/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5694e-05 - val_loss: 0.0013\n",
      "Epoch 917/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5688e-05 - val_loss: 0.0013\n",
      "Epoch 918/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5682e-05 - val_loss: 0.0013\n",
      "Epoch 919/1200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.5676e-05 - val_loss: 0.0013\n",
      "Epoch 920/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5669e-05 - val_loss: 0.0013\n",
      "Epoch 921/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5663e-05 - val_loss: 0.0013\n",
      "Epoch 922/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5657e-05 - val_loss: 0.0013\n",
      "Epoch 923/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5651e-05 - val_loss: 0.0013\n",
      "Epoch 924/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5645e-05 - val_loss: 0.0013\n",
      "Epoch 925/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5639e-05 - val_loss: 0.0013\n",
      "Epoch 926/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5634e-05 - val_loss: 0.0013\n",
      "Epoch 927/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5628e-05 - val_loss: 0.0013\n",
      "Epoch 928/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5622e-05 - val_loss: 0.0013\n",
      "Epoch 929/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5616e-05 - val_loss: 0.0013\n",
      "Epoch 930/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5611e-05 - val_loss: 0.0013\n",
      "Epoch 931/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5605e-05 - val_loss: 0.0013\n",
      "Epoch 932/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5600e-05 - val_loss: 0.0013\n",
      "Epoch 933/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5594e-05 - val_loss: 0.0013\n",
      "Epoch 934/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5589e-05 - val_loss: 0.0013\n",
      "Epoch 935/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5583e-05 - val_loss: 0.0013\n",
      "Epoch 936/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5578e-05 - val_loss: 0.0013\n",
      "Epoch 937/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5573e-05 - val_loss: 0.0013\n",
      "Epoch 938/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5567e-05 - val_loss: 0.0013\n",
      "Epoch 939/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5562e-05 - val_loss: 0.0013\n",
      "Epoch 940/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5557e-05 - val_loss: 0.0013\n",
      "Epoch 941/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5552e-05 - val_loss: 0.0013\n",
      "Epoch 942/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5546e-05 - val_loss: 0.0013\n",
      "Epoch 943/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5541e-05 - val_loss: 0.0013\n",
      "Epoch 944/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5536e-05 - val_loss: 0.0013\n",
      "Epoch 945/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5531e-05 - val_loss: 0.0013\n",
      "Epoch 946/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5526e-05 - val_loss: 0.0013\n",
      "Epoch 947/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5521e-05 - val_loss: 0.0013\n",
      "Epoch 948/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5516e-05 - val_loss: 0.0013\n",
      "Epoch 949/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5511e-05 - val_loss: 0.0013\n",
      "Epoch 950/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5506e-05 - val_loss: 0.0013\n",
      "Epoch 951/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5501e-05 - val_loss: 0.0013\n",
      "Epoch 952/1200\n",
      "5/5 [==============================] - 0s 986us/step - loss: 1.5496e-05 - val_loss: 0.0013\n",
      "Epoch 953/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5491e-05 - val_loss: 0.0013\n",
      "Epoch 954/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5486e-05 - val_loss: 0.0013\n",
      "Epoch 955/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5481e-05 - val_loss: 0.0013\n",
      "Epoch 956/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5476e-05 - val_loss: 0.0013\n",
      "Epoch 957/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5471e-05 - val_loss: 0.0013\n",
      "Epoch 958/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5466e-05 - val_loss: 0.0013\n",
      "Epoch 959/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5462e-05 - val_loss: 0.0013\n",
      "Epoch 960/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5457e-05 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5452e-05 - val_loss: 0.0013\n",
      "Epoch 962/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5447e-05 - val_loss: 0.0013\n",
      "Epoch 963/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5442e-05 - val_loss: 0.0013\n",
      "Epoch 964/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5437e-05 - val_loss: 0.0013\n",
      "Epoch 965/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5433e-05 - val_loss: 0.0013\n",
      "Epoch 966/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5428e-05 - val_loss: 0.0013\n",
      "Epoch 967/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5423e-05 - val_loss: 0.0013\n",
      "Epoch 968/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5419e-05 - val_loss: 0.0013\n",
      "Epoch 969/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5414e-05 - val_loss: 0.0013\n",
      "Epoch 970/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5409e-05 - val_loss: 0.0013\n",
      "Epoch 971/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5404e-05 - val_loss: 0.0013\n",
      "Epoch 972/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5400e-05 - val_loss: 0.0013\n",
      "Epoch 973/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5395e-05 - val_loss: 0.0013\n",
      "Epoch 974/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5390e-05 - val_loss: 0.0013\n",
      "Epoch 975/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5386e-05 - val_loss: 0.0013\n",
      "Epoch 976/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5381e-05 - val_loss: 0.0013\n",
      "Epoch 977/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5376e-05 - val_loss: 0.0013\n",
      "Epoch 978/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5372e-05 - val_loss: 0.0013\n",
      "Epoch 979/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5367e-05 - val_loss: 0.0013\n",
      "Epoch 980/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5363e-05 - val_loss: 0.0013\n",
      "Epoch 981/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5358e-05 - val_loss: 0.0013\n",
      "Epoch 982/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5353e-05 - val_loss: 0.0013\n",
      "Epoch 983/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5349e-05 - val_loss: 0.0013\n",
      "Epoch 984/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5344e-05 - val_loss: 0.0013\n",
      "Epoch 985/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5340e-05 - val_loss: 0.0013\n",
      "Epoch 986/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5335e-05 - val_loss: 0.0013\n",
      "Epoch 987/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5330e-05 - val_loss: 0.0013\n",
      "Epoch 988/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5326e-05 - val_loss: 0.0013\n",
      "Epoch 989/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5321e-05 - val_loss: 0.0013\n",
      "Epoch 990/1200\n",
      "5/5 [==============================] - 0s 974us/step - loss: 1.5317e-05 - val_loss: 0.0013\n",
      "Epoch 991/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5312e-05 - val_loss: 0.0013\n",
      "Epoch 992/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5308e-05 - val_loss: 0.0013\n",
      "Epoch 993/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5303e-05 - val_loss: 0.0013\n",
      "Epoch 994/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5298e-05 - val_loss: 0.0013\n",
      "Epoch 995/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5294e-05 - val_loss: 0.0013\n",
      "Epoch 996/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5289e-05 - val_loss: 0.0013\n",
      "Epoch 997/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5285e-05 - val_loss: 0.0013\n",
      "Epoch 998/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5280e-05 - val_loss: 0.0013\n",
      "Epoch 999/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5276e-05 - val_loss: 0.0013\n",
      "Epoch 1000/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5271e-05 - val_loss: 0.0013\n",
      "Epoch 1001/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5267e-05 - val_loss: 0.0013\n",
      "Epoch 1002/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5262e-05 - val_loss: 0.0013\n",
      "Epoch 1003/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5258e-05 - val_loss: 0.0013\n",
      "Epoch 1004/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5253e-05 - val_loss: 0.0013\n",
      "Epoch 1005/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5249e-05 - val_loss: 0.0013\n",
      "Epoch 1006/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5244e-05 - val_loss: 0.0013\n",
      "Epoch 1007/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5240e-05 - val_loss: 0.0013\n",
      "Epoch 1008/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5235e-05 - val_loss: 0.0013\n",
      "Epoch 1009/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5230e-05 - val_loss: 0.0013\n",
      "Epoch 1010/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5226e-05 - val_loss: 0.0013\n",
      "Epoch 1011/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5221e-05 - val_loss: 0.0013\n",
      "Epoch 1012/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5217e-05 - val_loss: 0.0013\n",
      "Epoch 1013/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5212e-05 - val_loss: 0.0013\n",
      "Epoch 1014/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5208e-05 - val_loss: 0.0013\n",
      "Epoch 1015/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5203e-05 - val_loss: 0.0013\n",
      "Epoch 1016/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5199e-05 - val_loss: 0.0013\n",
      "Epoch 1017/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5194e-05 - val_loss: 0.0013\n",
      "Epoch 1018/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5190e-05 - val_loss: 0.0013\n",
      "Epoch 1019/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5185e-05 - val_loss: 0.0013\n",
      "Epoch 1020/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5181e-05 - val_loss: 0.0013\n",
      "Epoch 1021/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5176e-05 - val_loss: 0.0013\n",
      "Epoch 1022/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5172e-05 - val_loss: 0.0013\n",
      "Epoch 1023/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5167e-05 - val_loss: 0.0013\n",
      "Epoch 1024/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5163e-05 - val_loss: 0.0013\n",
      "Epoch 1025/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5158e-05 - val_loss: 0.0013\n",
      "Epoch 1026/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5154e-05 - val_loss: 0.0013\n",
      "Epoch 1027/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5149e-05 - val_loss: 0.0013\n",
      "Epoch 1028/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5145e-05 - val_loss: 0.0013\n",
      "Epoch 1029/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5140e-05 - val_loss: 0.0013\n",
      "Epoch 1030/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5136e-05 - val_loss: 0.0013\n",
      "Epoch 1031/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5131e-05 - val_loss: 0.0013\n",
      "Epoch 1032/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5126e-05 - val_loss: 0.0013\n",
      "Epoch 1033/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5122e-05 - val_loss: 0.0013\n",
      "Epoch 1034/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5117e-05 - val_loss: 0.0013\n",
      "Epoch 1035/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5113e-05 - val_loss: 0.0013\n",
      "Epoch 1036/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5108e-05 - val_loss: 0.0013\n",
      "Epoch 1037/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5104e-05 - val_loss: 0.0013\n",
      "Epoch 1038/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5099e-05 - val_loss: 0.0013\n",
      "Epoch 1039/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5095e-05 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5090e-05 - val_loss: 0.0013\n",
      "Epoch 1041/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5086e-05 - val_loss: 0.0013\n",
      "Epoch 1042/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5081e-05 - val_loss: 0.0013\n",
      "Epoch 1043/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5077e-05 - val_loss: 0.0013\n",
      "Epoch 1044/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5072e-05 - val_loss: 0.0013\n",
      "Epoch 1045/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5068e-05 - val_loss: 0.0013\n",
      "Epoch 1046/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5063e-05 - val_loss: 0.0013\n",
      "Epoch 1047/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5058e-05 - val_loss: 0.0013\n",
      "Epoch 1048/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5054e-05 - val_loss: 0.0013\n",
      "Epoch 1049/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5049e-05 - val_loss: 0.0013\n",
      "Epoch 1050/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5045e-05 - val_loss: 0.0013\n",
      "Epoch 1051/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5040e-05 - val_loss: 0.0013\n",
      "Epoch 1052/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5036e-05 - val_loss: 0.0013\n",
      "Epoch 1053/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5031e-05 - val_loss: 0.0013\n",
      "Epoch 1054/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5027e-05 - val_loss: 0.0013\n",
      "Epoch 1055/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5022e-05 - val_loss: 0.0013\n",
      "Epoch 1056/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5017e-05 - val_loss: 0.0013\n",
      "Epoch 1057/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5013e-05 - val_loss: 0.0013\n",
      "Epoch 1058/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.5008e-05 - val_loss: 0.0013\n",
      "Epoch 1059/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5004e-05 - val_loss: 0.0013\n",
      "Epoch 1060/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4999e-05 - val_loss: 0.0013\n",
      "Epoch 1061/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4995e-05 - val_loss: 0.0013\n",
      "Epoch 1062/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4990e-05 - val_loss: 0.0013\n",
      "Epoch 1063/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4985e-05 - val_loss: 0.0013\n",
      "Epoch 1064/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4981e-05 - val_loss: 0.0013\n",
      "Epoch 1065/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4976e-05 - val_loss: 0.0013\n",
      "Epoch 1066/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4972e-05 - val_loss: 0.0013\n",
      "Epoch 1067/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4967e-05 - val_loss: 0.0013\n",
      "Epoch 1068/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4963e-05 - val_loss: 0.0013\n",
      "Epoch 1069/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4958e-05 - val_loss: 0.0013\n",
      "Epoch 1070/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4953e-05 - val_loss: 0.0013\n",
      "Epoch 1071/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4949e-05 - val_loss: 0.0013\n",
      "Epoch 1072/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4944e-05 - val_loss: 0.0013\n",
      "Epoch 1073/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4940e-05 - val_loss: 0.0013\n",
      "Epoch 1074/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4935e-05 - val_loss: 0.0013\n",
      "Epoch 1075/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4930e-05 - val_loss: 0.0013\n",
      "Epoch 1076/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4926e-05 - val_loss: 0.0013\n",
      "Epoch 1077/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4921e-05 - val_loss: 0.0013\n",
      "Epoch 1078/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4917e-05 - val_loss: 0.0013\n",
      "Epoch 1079/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4912e-05 - val_loss: 0.0013\n",
      "Epoch 1080/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4908e-05 - val_loss: 0.0013\n",
      "Epoch 1081/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4903e-05 - val_loss: 0.0013\n",
      "Epoch 1082/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4898e-05 - val_loss: 0.0013\n",
      "Epoch 1083/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4894e-05 - val_loss: 0.0012\n",
      "Epoch 1084/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4889e-05 - val_loss: 0.0012\n",
      "Epoch 1085/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4884e-05 - val_loss: 0.0012\n",
      "Epoch 1086/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4880e-05 - val_loss: 0.0012\n",
      "Epoch 1087/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4875e-05 - val_loss: 0.0012\n",
      "Epoch 1088/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4871e-05 - val_loss: 0.0012\n",
      "Epoch 1089/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4866e-05 - val_loss: 0.0012\n",
      "Epoch 1090/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4862e-05 - val_loss: 0.0012\n",
      "Epoch 1091/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4857e-05 - val_loss: 0.0012\n",
      "Epoch 1092/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4852e-05 - val_loss: 0.0012\n",
      "Epoch 1093/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4848e-05 - val_loss: 0.0012\n",
      "Epoch 1094/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4843e-05 - val_loss: 0.0012\n",
      "Epoch 1095/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4838e-05 - val_loss: 0.0012\n",
      "Epoch 1096/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4834e-05 - val_loss: 0.0012\n",
      "Epoch 1097/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4829e-05 - val_loss: 0.0012\n",
      "Epoch 1098/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4825e-05 - val_loss: 0.0012\n",
      "Epoch 1099/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4820e-05 - val_loss: 0.0012\n",
      "Epoch 1100/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4815e-05 - val_loss: 0.0012\n",
      "Epoch 1101/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4810e-05 - val_loss: 0.0012\n",
      "Epoch 1102/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4806e-05 - val_loss: 0.0012\n",
      "Epoch 1103/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4801e-05 - val_loss: 0.0012\n",
      "Epoch 1104/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4797e-05 - val_loss: 0.0012\n",
      "Epoch 1105/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4792e-05 - val_loss: 0.0012\n",
      "Epoch 1106/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4787e-05 - val_loss: 0.0012\n",
      "Epoch 1107/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4783e-05 - val_loss: 0.0012\n",
      "Epoch 1108/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4778e-05 - val_loss: 0.0012\n",
      "Epoch 1109/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4773e-05 - val_loss: 0.0012\n",
      "Epoch 1110/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4769e-05 - val_loss: 0.0012\n",
      "Epoch 1111/1200\n",
      "5/5 [==============================] - 0s 911us/step - loss: 1.4764e-05 - val_loss: 0.0012\n",
      "Epoch 1112/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4759e-05 - val_loss: 0.0012\n",
      "Epoch 1113/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4755e-05 - val_loss: 0.0012\n",
      "Epoch 1114/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4750e-05 - val_loss: 0.0012\n",
      "Epoch 1115/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4745e-05 - val_loss: 0.0012\n",
      "Epoch 1116/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4741e-05 - val_loss: 0.0012\n",
      "Epoch 1117/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4736e-05 - val_loss: 0.0012\n",
      "Epoch 1118/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4731e-05 - val_loss: 0.0012\n",
      "Epoch 1119/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4726e-05 - val_loss: 0.0012\n",
      "Epoch 1120/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4722e-05 - val_loss: 0.0012\n",
      "Epoch 1121/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4717e-05 - val_loss: 0.0012\n",
      "Epoch 1122/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4713e-05 - val_loss: 0.0012\n",
      "Epoch 1123/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4708e-05 - val_loss: 0.0012\n",
      "Epoch 1124/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4703e-05 - val_loss: 0.0012\n",
      "Epoch 1125/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4698e-05 - val_loss: 0.0012\n",
      "Epoch 1126/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4694e-05 - val_loss: 0.0012\n",
      "Epoch 1127/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4689e-05 - val_loss: 0.0012\n",
      "Epoch 1128/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4684e-05 - val_loss: 0.0012\n",
      "Epoch 1129/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4680e-05 - val_loss: 0.0012\n",
      "Epoch 1130/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4675e-05 - val_loss: 0.0012\n",
      "Epoch 1131/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4670e-05 - val_loss: 0.0012\n",
      "Epoch 1132/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4666e-05 - val_loss: 0.0012\n",
      "Epoch 1133/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4661e-05 - val_loss: 0.0012\n",
      "Epoch 1134/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4656e-05 - val_loss: 0.0012\n",
      "Epoch 1135/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4651e-05 - val_loss: 0.0012\n",
      "Epoch 1136/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4647e-05 - val_loss: 0.0012\n",
      "Epoch 1137/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4642e-05 - val_loss: 0.0012\n",
      "Epoch 1138/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4637e-05 - val_loss: 0.0012\n",
      "Epoch 1139/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4633e-05 - val_loss: 0.0012\n",
      "Epoch 1140/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4628e-05 - val_loss: 0.0012\n",
      "Epoch 1141/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4623e-05 - val_loss: 0.0012\n",
      "Epoch 1142/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4618e-05 - val_loss: 0.0012\n",
      "Epoch 1143/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4614e-05 - val_loss: 0.0012\n",
      "Epoch 1144/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4609e-05 - val_loss: 0.0012\n",
      "Epoch 1145/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4604e-05 - val_loss: 0.0012\n",
      "Epoch 1146/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4599e-05 - val_loss: 0.0012\n",
      "Epoch 1147/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4595e-05 - val_loss: 0.0012\n",
      "Epoch 1148/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4590e-05 - val_loss: 0.0012\n",
      "Epoch 1149/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4585e-05 - val_loss: 0.0012\n",
      "Epoch 1150/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4581e-05 - val_loss: 0.0012\n",
      "Epoch 1151/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4576e-05 - val_loss: 0.0012\n",
      "Epoch 1152/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4571e-05 - val_loss: 0.0012\n",
      "Epoch 1153/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4566e-05 - val_loss: 0.0012\n",
      "Epoch 1154/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4561e-05 - val_loss: 0.0012\n",
      "Epoch 1155/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4557e-05 - val_loss: 0.0012\n",
      "Epoch 1156/1200\n",
      "5/5 [==============================] - 0s 909us/step - loss: 1.4552e-05 - val_loss: 0.0012\n",
      "Epoch 1157/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4547e-05 - val_loss: 0.0012\n",
      "Epoch 1158/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4542e-05 - val_loss: 0.0012\n",
      "Epoch 1159/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4538e-05 - val_loss: 0.0012\n",
      "Epoch 1160/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4533e-05 - val_loss: 0.0012\n",
      "Epoch 1161/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4528e-05 - val_loss: 0.0012\n",
      "Epoch 1162/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4524e-05 - val_loss: 0.0012\n",
      "Epoch 1163/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4519e-05 - val_loss: 0.0012\n",
      "Epoch 1164/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4514e-05 - val_loss: 0.0012\n",
      "Epoch 1165/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4509e-05 - val_loss: 0.0012\n",
      "Epoch 1166/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4504e-05 - val_loss: 0.0012\n",
      "Epoch 1167/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4500e-05 - val_loss: 0.0012\n",
      "Epoch 1168/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4495e-05 - val_loss: 0.0012\n",
      "Epoch 1169/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4490e-05 - val_loss: 0.0012\n",
      "Epoch 1170/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4485e-05 - val_loss: 0.0012\n",
      "Epoch 1171/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4481e-05 - val_loss: 0.0012\n",
      "Epoch 1172/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4476e-05 - val_loss: 0.0012\n",
      "Epoch 1173/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4471e-05 - val_loss: 0.0012\n",
      "Epoch 1174/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4466e-05 - val_loss: 0.0012\n",
      "Epoch 1175/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4461e-05 - val_loss: 0.0012\n",
      "Epoch 1176/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4457e-05 - val_loss: 0.0012\n",
      "Epoch 1177/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4452e-05 - val_loss: 0.0012\n",
      "Epoch 1178/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4447e-05 - val_loss: 0.0012\n",
      "Epoch 1179/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4442e-05 - val_loss: 0.0012\n",
      "Epoch 1180/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4437e-05 - val_loss: 0.0012\n",
      "Epoch 1181/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4433e-05 - val_loss: 0.0012\n",
      "Epoch 1182/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4428e-05 - val_loss: 0.0012\n",
      "Epoch 1183/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4423e-05 - val_loss: 0.0012\n",
      "Epoch 1184/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4418e-05 - val_loss: 0.0012\n",
      "Epoch 1185/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4413e-05 - val_loss: 0.0012\n",
      "Epoch 1186/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4408e-05 - val_loss: 0.0012\n",
      "Epoch 1187/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4404e-05 - val_loss: 0.0012\n",
      "Epoch 1188/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4399e-05 - val_loss: 0.0012\n",
      "Epoch 1189/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4394e-05 - val_loss: 0.0012\n",
      "Epoch 1190/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4389e-05 - val_loss: 0.0012\n",
      "Epoch 1191/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4384e-05 - val_loss: 0.0012\n",
      "Epoch 1192/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4380e-05 - val_loss: 0.0012\n",
      "Epoch 1193/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4375e-05 - val_loss: 0.0012\n",
      "Epoch 1194/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4370e-05 - val_loss: 0.0012\n",
      "Epoch 1195/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4365e-05 - val_loss: 0.0012\n",
      "Epoch 1196/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4360e-05 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1197/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4355e-05 - val_loss: 0.0012\n",
      "Epoch 1198/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4350e-05 - val_loss: 0.0012\n",
      "Epoch 1199/1200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4346e-05 - val_loss: 0.0012\n",
      "Epoch 1200/1200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.4341e-05 - val_loss: 0.0012\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e5da080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "%matplotlib inline\n",
    " \n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1,1)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# fit model\n",
    "X,y = get_train()\n",
    "valX, valY = get_val()\n",
    "history = model.fit(X, y, epochs=1200, validation_data=(valX, valY), shuffle=False)\n",
    "# plot train and validation loss\n",
    "pyplot.plot(history.history['loss'][500:])\n",
    "pyplot.plot(history.history['val_loss'][500:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this example creates a plot showing the characteristic inflection point in validation loss of an overfit model.\n",
    "\n",
    "This may be a sign of too many training epochs.\n",
    "\n",
    "In this case, the model training could be stopped at the inflection point. Alternately, the number of training examples could be increased.\n",
    "\n",
    "## 6. Multiple Runs Example\n",
    "LSTMs are stochastic, meaning that you will get a different diagnostic plot each run.\n",
    "\n",
    "It can be useful to repeat the diagnostic run multiple times (e.g. 5, 10, or 30). The train and validation traces from each run can then be plotted to give a more robust idea of the behavior of the model over time.\n",
    "\n",
    "The example below runs the same experiment a number of times before plotting the trace of train and validation loss for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 329ms/step - loss: 0.1317 - val_loss: 0.8211\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 994us/step - loss: 0.1303 - val_loss: 0.8162\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1290 - val_loss: 0.8113\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 847us/step - loss: 0.1276 - val_loss: 0.8064\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 906us/step - loss: 0.1263 - val_loss: 0.8016\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1250 - val_loss: 0.7967\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1237 - val_loss: 0.7920\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.7872\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.1211 - val_loss: 0.7825\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1198 - val_loss: 0.7778\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1185 - val_loss: 0.7731\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.1172 - val_loss: 0.7685\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 907us/step - loss: 0.1160 - val_loss: 0.7639\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1148 - val_loss: 0.7593\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.1135 - val_loss: 0.7548\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 917us/step - loss: 0.1123 - val_loss: 0.7503\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1111 - val_loss: 0.7458\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1099 - val_loss: 0.7413\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 884us/step - loss: 0.1087 - val_loss: 0.7369\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1076 - val_loss: 0.7325\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.1064 - val_loss: 0.7281\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1053 - val_loss: 0.7238\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1041 - val_loss: 0.7195\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 883us/step - loss: 0.1030 - val_loss: 0.7152\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 959us/step - loss: 0.1019 - val_loss: 0.7109\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.7066\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 879us/step - loss: 0.0996 - val_loss: 0.7024\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0985 - val_loss: 0.6982\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0975 - val_loss: 0.6940\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 882us/step - loss: 0.0964 - val_loss: 0.6899\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 987us/step - loss: 0.0953 - val_loss: 0.6857\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.6816\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 916us/step - loss: 0.0932 - val_loss: 0.6775\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0922 - val_loss: 0.6734\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 886us/step - loss: 0.0911 - val_loss: 0.6694\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.6654\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 926us/step - loss: 0.0891 - val_loss: 0.6613\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.0881 - val_loss: 0.6573\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0871 - val_loss: 0.6534\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.6494\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.6454\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 949us/step - loss: 0.0841 - val_loss: 0.6415\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.6376\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 950us/step - loss: 0.0822 - val_loss: 0.6337\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0812 - val_loss: 0.6298\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0803 - val_loss: 0.6259\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0793 - val_loss: 0.6221\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.6182\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0775 - val_loss: 0.6144\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.6106\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.6068\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.6030\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.5993\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0730 - val_loss: 0.5955\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.5918\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.5881\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.5844\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.5807\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.5771\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.5734\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0670 - val_loss: 0.5698\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0662 - val_loss: 0.5662\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.5625\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.5589\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0637 - val_loss: 0.5553\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.5518\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0621 - val_loss: 0.5482\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0614 - val_loss: 0.5446\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.5411\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.5376\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.5341\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.5306\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.5271\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0568 - val_loss: 0.5236\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0561 - val_loss: 0.5201\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.5166\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 978us/step - loss: 0.0546 - val_loss: 0.5132\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0539 - val_loss: 0.5097\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0532 - val_loss: 0.5063\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0525 - val_loss: 0.5029\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.4994\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.0511 - val_loss: 0.4961\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.4927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.4893\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.4859\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.4826\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.4792\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.4759\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.4726\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.0459 - val_loss: 0.4693\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.4660\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.4627\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.4594\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.4561\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.4529\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.0423 - val_loss: 0.4496\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 959us/step - loss: 0.0417 - val_loss: 0.4464\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 886us/step - loss: 0.0411 - val_loss: 0.4432\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.4399\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.4367\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.4336\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0389 - val_loss: 0.4304\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0383 - val_loss: 0.4272\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0378 - val_loss: 0.4241\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0373 - val_loss: 0.4209\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 897us/step - loss: 0.0368 - val_loss: 0.4178\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.4147\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.4116\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.4085\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 962us/step - loss: 0.0348 - val_loss: 0.4054\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0343 - val_loss: 0.4024\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.3993\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.3963\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.3933\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0324 - val_loss: 0.3903\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.3873\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.0315 - val_loss: 0.3843\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 875us/step - loss: 0.0311 - val_loss: 0.3814\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0307 - val_loss: 0.3784\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.3755\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.3726\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.3697\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.3668\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.3640\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.3611\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.3583\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.3555\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0272 - val_loss: 0.3527\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.3499\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.3472\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.3444\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.3417\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.3390\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.3364\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0248 - val_loss: 0.3337\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 889us/step - loss: 0.0245 - val_loss: 0.3310\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.3284\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0239 - val_loss: 0.3258\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.3233\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 835us/step - loss: 0.0234 - val_loss: 0.3207\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.3182\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.3156\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 909us/step - loss: 0.0226 - val_loss: 0.3131\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.3107\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.3082\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.3058\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 901us/step - loss: 0.0216 - val_loss: 0.3034\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0213 - val_loss: 0.3010\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0211 - val_loss: 0.2986\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0209 - val_loss: 0.2963\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 946us/step - loss: 0.0207 - val_loss: 0.2940\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.2917\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.2894\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.2872\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.2850\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2828\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0195 - val_loss: 0.2806\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.2785\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.2764\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.2743\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.2722\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 934us/step - loss: 0.0187 - val_loss: 0.2701\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.2681\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.2661\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.2642\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.2622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.2603\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.2584\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.2565\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.2547\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.2529\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.2511\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.2493\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.2476\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2458\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.2442\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.2425\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.2409\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.2392\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2376\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.2361\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2345\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2330\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.2315\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.2301\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.2286\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.2272\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.2258\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.2244\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.2231\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.2217\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.2204\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.2191\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.2179\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.2166\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 939us/step - loss: 0.0155 - val_loss: 0.2154\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.2142\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.2131\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.2119\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2108\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.2096\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2086\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.2075\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2064\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2054\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2044\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2034\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.2024\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2014\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2005\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.1995\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.1986\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.1977\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.1968\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.1959\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 929us/step - loss: 0.0147 - val_loss: 0.1951\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.1943\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.1934\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.1926\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 933us/step - loss: 0.0145 - val_loss: 0.1918\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1910\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.1902\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1895\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.1887\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 862us/step - loss: 0.0143 - val_loss: 0.1880\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0143 - val_loss: 0.1873\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.1865\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.1858\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1851\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1845\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1838\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.1831\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.1824\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1818\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1811\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1805\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1799\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1793\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1786\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1780\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.1774\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.1768\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1762\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1757\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.1751\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1745\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1739\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1734\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1722\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1717\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1711\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.1706\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1701\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.0133 - val_loss: 0.1695\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1690\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1684\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.1679\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1674\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1668\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1663\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1658\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1653\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1647\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1642\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1637\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.1632\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1627\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.1622\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1616\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1611\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1606\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.1601\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1596\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1591\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1586\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1581\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1575\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1570\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1565\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1560\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1555\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1550\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1545\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1540\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1535\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1529\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1524\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1519\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1514\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1509\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1504\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1499\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1493\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1488\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1483\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1478\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1473\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1468\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1462\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 337ms/step - loss: 0.1100 - val_loss: 0.6542\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1089 - val_loss: 0.6489\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.1075 - val_loss: 0.6436\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 863us/step - loss: 0.1060 - val_loss: 0.6383\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.1046 - val_loss: 0.6331\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.6280\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1018 - val_loss: 0.6228\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.6177\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.0990 - val_loss: 0.6126\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0976 - val_loss: 0.6075\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0962 - val_loss: 0.6024\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0948 - val_loss: 0.5973\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.5922\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.5872\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0908 - val_loss: 0.5821\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.5772\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.5722\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.5673\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0856 - val_loss: 0.5623\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.5574\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 882us/step - loss: 0.0831 - val_loss: 0.5526\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.5477\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.5429\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.5381\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.5333\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.5285\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 980us/step - loss: 0.0757 - val_loss: 0.5238\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.5191\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.5144\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.5098\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.5052\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0700 - val_loss: 0.5006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0689 - val_loss: 0.4960\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.4915\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.4870\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.4826\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.4782\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.4738\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0625 - val_loss: 0.4695\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0615 - val_loss: 0.4651\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.4608\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.4566\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 957us/step - loss: 0.0585 - val_loss: 0.4523\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.4481\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 922us/step - loss: 0.0565 - val_loss: 0.4439\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0556 - val_loss: 0.4397\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0547 - val_loss: 0.4356\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.4315\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.4274\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.4233\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.4193\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.4153\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.4113\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.4074\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.4035\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 940us/step - loss: 0.0468 - val_loss: 0.3996\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.3957\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.3919\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0444 - val_loss: 0.3881\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.3843\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.3806\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.3769\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.3732\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.3695\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.3659\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0391 - val_loss: 0.3622\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0384 - val_loss: 0.3587\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.3551\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0371 - val_loss: 0.3516\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0364 - val_loss: 0.3481\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0357 - val_loss: 0.3446\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.3411\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 901us/step - loss: 0.0344 - val_loss: 0.3377\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0338 - val_loss: 0.3343\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.3310\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0326 - val_loss: 0.3276\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0320 - val_loss: 0.3243\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0314 - val_loss: 0.3210\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0309 - val_loss: 0.3178\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.3146\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.0297 - val_loss: 0.3114\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0292 - val_loss: 0.3082\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0287 - val_loss: 0.3051\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.0281 - val_loss: 0.3019\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0276 - val_loss: 0.2989\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.2958\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0266 - val_loss: 0.2928\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0262 - val_loss: 0.2898\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0257 - val_loss: 0.2868\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.2839\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0248 - val_loss: 0.2810\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.2781\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.2752\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0235 - val_loss: 0.2724\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.2696\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.2668\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0223 - val_loss: 0.2641\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 931us/step - loss: 0.0219 - val_loss: 0.2614\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2587\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0211 - val_loss: 0.2560\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 962us/step - loss: 0.0208 - val_loss: 0.2534\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.2508\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.2483\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.2457\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0194 - val_loss: 0.2432\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.2408\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.2383\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.2359\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.2335\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.2312\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.2288\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 917us/step - loss: 0.0174 - val_loss: 0.2265\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 981us/step - loss: 0.0171 - val_loss: 0.2243\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 883us/step - loss: 0.0169 - val_loss: 0.2220\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2198\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2177\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.2155\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.2134\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 957us/step - loss: 0.0157 - val_loss: 0.2113\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2092\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.2072\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2052\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2032\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.2013\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.1993\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.1975\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.1956\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.1938\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1920\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1902\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0135 - val_loss: 0.1884\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1867\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 964us/step - loss: 0.0133 - val_loss: 0.1850\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1833\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1817\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1801\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 985us/step - loss: 0.0127 - val_loss: 0.1785\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1769\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1754\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1739\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1724\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.0122 - val_loss: 0.1709\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1695\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1681\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1667\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1653\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1640\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1626\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1614\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1601\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1588\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1576\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1564\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1552\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1541\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1529\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1518\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1507\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1496\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1486\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1475\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1465\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1455\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1445\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1436\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1426\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1417\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1408\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1399\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1390\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1382\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1373\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1365\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1357\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1349\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1341\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.0102 - val_loss: 0.1333\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1326\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1318\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1311\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1304\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1297\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1290\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 935us/step - loss: 0.0099 - val_loss: 0.1283\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1277\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1270\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1264\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 918us/step - loss: 0.0098 - val_loss: 0.1257\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1251\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0098 - val_loss: 0.1245\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1239\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1233\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1227\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1222\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1216\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 888us/step - loss: 0.0096 - val_loss: 0.1211\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1205\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 979us/step - loss: 0.0096 - val_loss: 0.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 898us/step - loss: 0.0095 - val_loss: 0.1195\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.0095 - val_loss: 0.1189\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1184\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1179\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0094 - val_loss: 0.1174\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1169\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1164\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1160\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 950us/step - loss: 0.0093 - val_loss: 0.1155\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1150\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1145\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1141\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1136\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1132\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1128\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1123\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1119\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1115\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1110\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1106\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1102\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1098\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1094\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1090\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1086\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1082\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1078\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1074\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1070\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1066\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0088 - val_loss: 0.1062\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1058\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1055\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0087 - val_loss: 0.1051\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1047\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1043\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1040\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1036\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1032\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1029\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1025\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1021\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1018\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1014\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1011\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1007\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1003\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1000\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0996\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0993\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0989\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.0986\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0982\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0979\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 943us/step - loss: 0.0082 - val_loss: 0.0975\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 825us/step - loss: 0.0082 - val_loss: 0.0972\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.0968\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0965\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0961\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0958\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0954\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 845us/step - loss: 0.0080 - val_loss: 0.0951\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0080 - val_loss: 0.0947\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 935us/step - loss: 0.0080 - val_loss: 0.0944\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 841us/step - loss: 0.0080 - val_loss: 0.0941\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0937\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.0079 - val_loss: 0.0934\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0930\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0927\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0923\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 971us/step - loss: 0.0078 - val_loss: 0.0920\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0917\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0913\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0910\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0906\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0903\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 931us/step - loss: 0.0077 - val_loss: 0.0900\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0896\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0893\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0076 - val_loss: 0.0889\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0886\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0883\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0876\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 916us/step - loss: 0.0075 - val_loss: 0.0873\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0869\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.0074 - val_loss: 0.0866\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0862\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0859\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0856\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0852\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0073 - val_loss: 0.0849\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 944us/step - loss: 0.0073 - val_loss: 0.0846\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0842\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 886us/step - loss: 0.0072 - val_loss: 0.0839\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0835\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0072 - val_loss: 0.0832\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0071 - val_loss: 0.0829\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 986us/step - loss: 0.0071 - val_loss: 0.0825\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0071 - val_loss: 0.0822\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 921us/step - loss: 0.0071 - val_loss: 0.0819\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 972us/step - loss: 0.0070 - val_loss: 0.0815\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 328ms/step - loss: 0.1172 - val_loss: 0.7102\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.1163 - val_loss: 0.7061\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 851us/step - loss: 0.1151 - val_loss: 0.7014\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1138 - val_loss: 0.6968\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.6922\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1113 - val_loss: 0.6876\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.6830\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1088 - val_loss: 0.6784\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1075 - val_loss: 0.6739\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1063 - val_loss: 0.6694\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1051 - val_loss: 0.6650\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1039 - val_loss: 0.6605\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1027 - val_loss: 0.6561\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.6517\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1003 - val_loss: 0.6474\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0991 - val_loss: 0.6430\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 878us/step - loss: 0.0980 - val_loss: 0.6387\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.6345\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0957 - val_loss: 0.6302\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.6260\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0935 - val_loss: 0.6218\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0924 - val_loss: 0.6176\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0913 - val_loss: 0.6135\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.6094\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.6052\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0881 - val_loss: 0.6012\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0870 - val_loss: 0.5971\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.5931\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.5891\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0839 - val_loss: 0.5852\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0829 - val_loss: 0.5812\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.5773\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 958us/step - loss: 0.0809 - val_loss: 0.5734\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0799 - val_loss: 0.5696\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0790 - val_loss: 0.5657\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.5619\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0770 - val_loss: 0.5581\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.5544\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.5506\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.5469\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.5432\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.5395\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.5358\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 965us/step - loss: 0.0706 - val_loss: 0.5321\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.5285\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.5249\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0679 - val_loss: 0.5213\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0671 - val_loss: 0.5178\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.5142\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.5107\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.5072\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.5037\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0629 - val_loss: 0.5002\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0621 - val_loss: 0.4968\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 924us/step - loss: 0.0613 - val_loss: 0.4933\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.4899\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.0597 - val_loss: 0.4865\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0589 - val_loss: 0.4831\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.4797\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 923us/step - loss: 0.0574 - val_loss: 0.4764\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 915us/step - loss: 0.0566 - val_loss: 0.4730\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 929us/step - loss: 0.0559 - val_loss: 0.4697\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 938us/step - loss: 0.0551 - val_loss: 0.4664\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0544 - val_loss: 0.4631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0537 - val_loss: 0.4598\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0529 - val_loss: 0.4565\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.4533\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.4500\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.4468\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.4436\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.4404\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0487 - val_loss: 0.4372\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.4340\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0474 - val_loss: 0.4308\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 942us/step - loss: 0.0467 - val_loss: 0.4277\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0461 - val_loss: 0.4246\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.4214\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.4183\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.4152\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.4122\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.4091\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.4060\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.4030\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.4000\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0405 - val_loss: 0.3969\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.3939\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.3910\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0388 - val_loss: 0.3880\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.3850\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0377 - val_loss: 0.3821\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0371 - val_loss: 0.3791\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.3762\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0361 - val_loss: 0.3733\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - val_loss: 0.3704\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.3675\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.3646\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.3618\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0335 - val_loss: 0.3590\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.3561\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0325 - val_loss: 0.3533\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0321 - val_loss: 0.3505\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0316 - val_loss: 0.3477\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0311 - val_loss: 0.3450\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.3422\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.3395\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.3368\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0294 - val_loss: 0.3341\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.3314\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.3287\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0281 - val_loss: 0.3261\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.3234\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0273 - val_loss: 0.3208\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.3182\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.3156\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.3130\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0258 - val_loss: 0.3105\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 942us/step - loss: 0.0254 - val_loss: 0.3080\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.3054\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.3029\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.3005\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.2980\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.2956\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0234 - val_loss: 0.2931\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.2907\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.2883\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.2860\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.2836\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.2813\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2790\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.2767\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.2744\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.2722\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.2700\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.2678\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.2656\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.2634\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.2613\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.2591\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.2570\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.2550\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.2529\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.2509\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.2489\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.2469\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.2449\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.2429\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.2410\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.2391\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.2372\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.2354\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.2335\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.2317\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.0165 - val_loss: 0.2299\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.2282\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.2264\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2247\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.2230\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 875us/step - loss: 0.0158 - val_loss: 0.2213\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0156 - val_loss: 0.2196\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2180\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.2164\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.2148\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.2132\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2117\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0149 - val_loss: 0.2102\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 955us/step - loss: 0.0148 - val_loss: 0.2087\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0147 - val_loss: 0.2072\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.2057\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.2043\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2029\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.2015\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2001\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0142 - val_loss: 0.1987\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1974\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 963us/step - loss: 0.0141 - val_loss: 0.1961\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 820us/step - loss: 0.0140 - val_loss: 0.1948\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1935\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0139 - val_loss: 0.1923\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1910\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1898\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1886\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0136 - val_loss: 0.1875\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1863\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0135 - val_loss: 0.1852\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 886us/step - loss: 0.0134 - val_loss: 0.1841\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1830\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0133 - val_loss: 0.1819\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1808\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1798\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1788\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1778\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.1768\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1758\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1748\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0130 - val_loss: 0.1739\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1730\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1721\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.1712\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1703\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1695\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1686\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1678\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.1670\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1662\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1654\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1646\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1638\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1631\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1623\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1616\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1609\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1602\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1595\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1588\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1582\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1575\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1568\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1562\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.1556\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1550\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1543\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1537\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1532\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1526\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1520\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1514\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0120 - val_loss: 0.1509\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1503\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1498\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1487\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1482\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1477\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1472\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1467\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1462\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1457\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1452\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1447\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1442\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1438\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1433\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1428\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1424\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1419\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1415\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1410\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.0114 - val_loss: 0.1406\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1401\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1397\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1393\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1388\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1384\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1380\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1376\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1372\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1367\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1363\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1359\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1355\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1351\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1347\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1343\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1339\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1335\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1331\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1327\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1323\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1319\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1316\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1312\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1308\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1304\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0108 - val_loss: 0.1300\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1296\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1292\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1289\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1285\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1281\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1277\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.0106 - val_loss: 0.1274\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1270\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 887us/step - loss: 0.0106 - val_loss: 0.1266\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0105 - val_loss: 0.1262\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 892us/step - loss: 0.0105 - val_loss: 0.1258\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1255\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1251\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 904us/step - loss: 0.0104 - val_loss: 0.1247\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1244\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1240\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1236\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1232\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 939us/step - loss: 0.0103 - val_loss: 0.1229\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 860us/step - loss: 0.0103 - val_loss: 0.1225\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.0103 - val_loss: 0.1221\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 905us/step - loss: 0.0102 - val_loss: 0.1218\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1214\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1210\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1207\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1203\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 352ms/step - loss: 0.1102 - val_loss: 0.6577\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1088 - val_loss: 0.6536\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 976us/step - loss: 0.1077 - val_loss: 0.6489\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 922us/step - loss: 0.1064 - val_loss: 0.6442\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1050 - val_loss: 0.6396\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1037 - val_loss: 0.6349\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1024 - val_loss: 0.6304\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1012 - val_loss: 0.6258\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.6213\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0986 - val_loss: 0.6167\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 936us/step - loss: 0.0974 - val_loss: 0.6122\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0961 - val_loss: 0.6077\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0949 - val_loss: 0.6032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0936 - val_loss: 0.5987\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 982us/step - loss: 0.0924 - val_loss: 0.5943\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0912 - val_loss: 0.5899\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.5855\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0889 - val_loss: 0.5811\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.5768\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.5724\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0854 - val_loss: 0.5682\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0842 - val_loss: 0.5639\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.5597\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0820 - val_loss: 0.5555\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.5513\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0798 - val_loss: 0.5471\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.5429\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 979us/step - loss: 0.0776 - val_loss: 0.5388\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0766 - val_loss: 0.5347\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.5307\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.5266\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 947us/step - loss: 0.0734 - val_loss: 0.5226\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 954us/step - loss: 0.0724 - val_loss: 0.5186\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.5147\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.5107\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.5068\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.5029\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0675 - val_loss: 0.4990\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0665 - val_loss: 0.4951\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.4913\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0646 - val_loss: 0.4875\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0637 - val_loss: 0.4838\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0628 - val_loss: 0.4800\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0619 - val_loss: 0.4762\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0610 - val_loss: 0.4725\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.4689\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.4652\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.4616\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.4580\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0567 - val_loss: 0.4544\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0559 - val_loss: 0.4508\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.4472\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0542 - val_loss: 0.4437\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0534 - val_loss: 0.4402\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.4367\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0518 - val_loss: 0.4332\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.4298\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.4264\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.4230\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.4196\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.4162\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0473 - val_loss: 0.4129\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.4096\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.4063\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.4030\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.3997\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.3965\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.3933\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.3901\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.3869\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.3837\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.3806\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 925us/step - loss: 0.0398 - val_loss: 0.3774\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 978us/step - loss: 0.0392 - val_loss: 0.3743\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0386 - val_loss: 0.3712\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0380 - val_loss: 0.3681\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0374 - val_loss: 0.3651\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.3621\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0362 - val_loss: 0.3591\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0356 - val_loss: 0.3561\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.3531\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0345 - val_loss: 0.3501\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.3472\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0334 - val_loss: 0.3443\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0329 - val_loss: 0.3414\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.3385\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0318 - val_loss: 0.3357\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.3328\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.3300\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0303 - val_loss: 0.3272\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.3244\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0294 - val_loss: 0.3217\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.3189\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.3162\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.3135\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.3108\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.3082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.3055\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.3029\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.3003\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.2978\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.2952\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.2927\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0243 - val_loss: 0.2902\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.2877\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.2852\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.2828\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0228 - val_loss: 0.2803\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.2779\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.2755\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.2732\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.2708\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.2685\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.2662\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 975us/step - loss: 0.0206 - val_loss: 0.2639\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.2617\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.2595\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.2573\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.2551\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.2529\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.2508\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.2487\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.2466\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.2445\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.2424\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2404\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.2384\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.2364\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.2345\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.2325\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.2306\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2287\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.2268\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.2250\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.2232\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 981us/step - loss: 0.0157 - val_loss: 0.2214\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.2196\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.2179\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.2161\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2144\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.2127\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0147 - val_loss: 0.2111\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.2094\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.2078\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0143 - val_loss: 0.2062\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.2046\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 938us/step - loss: 0.0141 - val_loss: 0.2031\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0140 - val_loss: 0.2015\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.2000\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0137 - val_loss: 0.1985\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1971\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.1956\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0134 - val_loss: 0.1942\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 951us/step - loss: 0.0133 - val_loss: 0.1928\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1914\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1901\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.1887\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1874\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1861\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 886us/step - loss: 0.0128 - val_loss: 0.1848\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1836\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0126 - val_loss: 0.1823\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1811\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.1799\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.1788\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.1776\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.1764\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.1753\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.1742\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0121 - val_loss: 0.1731\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1721\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.1710\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1700\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0119 - val_loss: 0.1690\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.1680\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1670\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1660\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0117 - val_loss: 0.1651\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1641\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0116 - val_loss: 0.1632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1623\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1614\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.1606\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1597\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0114 - val_loss: 0.1589\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1580\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1572\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0113 - val_loss: 0.1564\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1557\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.1549\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1541\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1534\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1526\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1519\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1512\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.1505\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1498\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1491\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1485\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1478\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1472\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1465\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1459\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1453\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1447\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1441\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1435\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1429\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1423\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1418\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.1412\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1407\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1401\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1396\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1391\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1386\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1380\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0104 - val_loss: 0.1375\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1370\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1365\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1361\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1356\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1351\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1346\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1342\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1337\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.1332\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1328\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1323\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1319\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1315\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1310\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1306\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1302\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1297\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1293\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1289\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1285\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.1281\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1277\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1273\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1269\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1265\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1261\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1257\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1253\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1249\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1245\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1241\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1237\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1234\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1230\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1226\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1222\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1219\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1215\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1211\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1207\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1204\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.1200\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1196\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1193\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1185\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1182\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1178\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1175\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.1171\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1167\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1164\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1160\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1157\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1153\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1149\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1146\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.1142\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1139\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1135\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1132\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1128\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1125\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1121\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.1118\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1114\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1111\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1107\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1104\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1100\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1097\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1093\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1090\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.1086\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1083\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1079\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1076\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.1072\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1069\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1065\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1062\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.1058\n",
      "Train on 5 samples, validate on 5 samples\n",
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 361ms/step - loss: 0.1070 - val_loss: 0.6332\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 913us/step - loss: 0.1061 - val_loss: 0.6290\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.6252\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 919us/step - loss: 0.1038 - val_loss: 0.6211\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1026 - val_loss: 0.6169\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 978us/step - loss: 0.1014 - val_loss: 0.6128\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 866us/step - loss: 0.1002 - val_loss: 0.6087\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 923us/step - loss: 0.0990 - val_loss: 0.6046\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.0979 - val_loss: 0.6005\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0967 - val_loss: 0.5964\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0956 - val_loss: 0.5923\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.5883\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0933 - val_loss: 0.5842\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 847us/step - loss: 0.0921 - val_loss: 0.5802\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 915us/step - loss: 0.0910 - val_loss: 0.5761\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 977us/step - loss: 0.0899 - val_loss: 0.5721\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 973us/step - loss: 0.0888 - val_loss: 0.5681\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 912us/step - loss: 0.0877 - val_loss: 0.5641\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 969us/step - loss: 0.0866 - val_loss: 0.5600\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 932us/step - loss: 0.0855 - val_loss: 0.5560\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.5521\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.5481\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.5442\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 991us/step - loss: 0.0812 - val_loss: 0.5402\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.5363\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.5324\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.5285\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.5246\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.5207\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0751 - val_loss: 0.5169\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.5130\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.5092\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.5054\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.5016\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.4978\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0692 - val_loss: 0.4940\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.4902\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.4865\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.4827\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0654 - val_loss: 0.4789\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0645 - val_loss: 0.4752\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0636 - val_loss: 0.4715\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0627 - val_loss: 0.4678\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.4642\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0609 - val_loss: 0.4605\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.4568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.4532\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.4495\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.4459\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.4423\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0557 - val_loss: 0.4387\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.4352\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0540 - val_loss: 0.4316\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 929us/step - loss: 0.0532 - val_loss: 0.4281\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0524 - val_loss: 0.4245\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.4210\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 957us/step - loss: 0.0508 - val_loss: 0.4175\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 980us/step - loss: 0.0500 - val_loss: 0.4140\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 815us/step - loss: 0.0492 - val_loss: 0.4106\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.4071\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.4036\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0470 - val_loss: 0.4002\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 927us/step - loss: 0.0462 - val_loss: 0.3968\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.3934\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.3900\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.3866\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.3832\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.3799\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.3766\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.3732\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.3699\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 974us/step - loss: 0.0399 - val_loss: 0.3666\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0392 - val_loss: 0.3634\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.3601\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0379 - val_loss: 0.3569\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.3536\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0367 - val_loss: 0.3504\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0360 - val_loss: 0.3472\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.3441\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 880us/step - loss: 0.0348 - val_loss: 0.3409\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0342 - val_loss: 0.3378\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.3347\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 934us/step - loss: 0.0331 - val_loss: 0.3316\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0325 - val_loss: 0.3285\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.3255\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 967us/step - loss: 0.0314 - val_loss: 0.3224\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.3194\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.3164\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0298 - val_loss: 0.3134\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0293 - val_loss: 0.3105\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.3075\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.3046\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0278 - val_loss: 0.3017\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.2988\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.2960\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0264 - val_loss: 0.2932\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0259 - val_loss: 0.2903\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.2876\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0250 - val_loss: 0.2848\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.2820\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0242 - val_loss: 0.2793\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.2766\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.2740\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.2713\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.2687\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.2661\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.2635\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.2609\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.2584\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.2559\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.2534\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.2510\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.2485\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.2461\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.2437\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.2414\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.2390\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.2367\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.2345\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.2322\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.2300\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.2278\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.2256\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.2234\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.2213\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.2192\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 952us/step - loss: 0.0160 - val_loss: 0.2171\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.2151\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.2131\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.2111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.2091\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.2072\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.2053\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.2034\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.2015\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.1997\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0141 - val_loss: 0.1979\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.1961\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0138 - val_loss: 0.1943\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.1926\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 894us/step - loss: 0.0135 - val_loss: 0.1908\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0133 - val_loss: 0.1892\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0132 - val_loss: 0.1875\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0131 - val_loss: 0.1859\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0129 - val_loss: 0.1843\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0128 - val_loss: 0.1827\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0127 - val_loss: 0.1811\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0126 - val_loss: 0.1796\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0125 - val_loss: 0.1781\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0124 - val_loss: 0.1766\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0123 - val_loss: 0.1752\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0122 - val_loss: 0.1737\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.1723\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0120 - val_loss: 0.1710\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.1696\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0118 - val_loss: 0.1683\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.1670\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1657\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0116 - val_loss: 0.1644\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.1631\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0114 - val_loss: 0.1619\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1607\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0113 - val_loss: 0.1595\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.1584\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.1572\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.1561\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1550\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.1539\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.1529\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0109 - val_loss: 0.1519\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1508\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0108 - val_loss: 0.1498\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.1489\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.1479\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1470\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.1460\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1451\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.1442\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.1434\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1425\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.1417\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1408\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.1400\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0103 - val_loss: 0.1392\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1384\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1377\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.1369\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1362\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0101 - val_loss: 0.1355\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.1348\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1341\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1334\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.1327\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0100 - val_loss: 0.1320\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1314\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1308\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.1301\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1295\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1289\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1283\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.1277\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1272\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1266\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1260\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.1255\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1249\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1244\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.1239\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.1234\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1229\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1224\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.1219\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.1214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1209\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1204\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1200\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.1195\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1191\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1186\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1182\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.1177\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.1173\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1169\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1164\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1160\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.1156\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.1152\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1148\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1144\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.1140\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1136\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1132\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1128\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.1124\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1120\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1117\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.1113\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1109\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.1105\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1102\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1098\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.1094\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 941us/step - loss: 0.0088 - val_loss: 0.1091\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1087\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.1083\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1080\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.1076\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1073\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 949us/step - loss: 0.0086 - val_loss: 0.1069\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1066\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.1062\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1059\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1055\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1052\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.1048\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.1045\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1041\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 972us/step - loss: 0.0084 - val_loss: 0.1038\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 960us/step - loss: 0.0084 - val_loss: 0.1035\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0084 - val_loss: 0.1031\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1028\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 970us/step - loss: 0.0083 - val_loss: 0.1024\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1021\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0083 - val_loss: 0.1018\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 946us/step - loss: 0.0082 - val_loss: 0.1014\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0082 - val_loss: 0.1011\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1007\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0082 - val_loss: 0.1004\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.1001\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 908us/step - loss: 0.0081 - val_loss: 0.0997\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0081 - val_loss: 0.0994\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0991\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0987\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0984\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0080 - val_loss: 0.0981\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0977\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0974\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0971\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0079 - val_loss: 0.0967\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 932us/step - loss: 0.0079 - val_loss: 0.0964\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 961us/step - loss: 0.0079 - val_loss: 0.0961\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0078 - val_loss: 0.0957\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0954\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0951\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0078 - val_loss: 0.0947\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 962us/step - loss: 0.0077 - val_loss: 0.0944\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0077 - val_loss: 0.0941\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0937\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0077 - val_loss: 0.0934\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0931\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0927\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0924\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0076 - val_loss: 0.0921\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0917\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0914\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0075 - val_loss: 0.0907\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0904\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 942us/step - loss: 0.0074 - val_loss: 0.0901\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.0898\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1203d76a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    "from pandas import DataFrame\n",
    "%matplotlib inline\n",
    " \n",
    "# return training data\n",
    "def get_train():\n",
    "\tseq = [[0.0, 0.1], [0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((5, 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# return validation data\n",
    "def get_val():\n",
    "\tseq = [[0.5, 0.6], [0.6, 0.7], [0.7, 0.8], [0.8, 0.9], [0.9, 1.0]]\n",
    "\tseq = array(seq)\n",
    "\tX, y = seq[:, 0], seq[:, 1]\n",
    "\tX = X.reshape((len(X), 1, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# collect data across multiple repeats\n",
    "train = DataFrame()\n",
    "val = DataFrame()\n",
    "for i in range(5):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(10, input_shape=(1,1)))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\tX,y = get_train()\n",
    "\tvalX, valY = get_val()\n",
    "\t# fit model\n",
    "\thistory = model.fit(X, y, epochs=300, validation_data=(valX, valY), shuffle=False)\n",
    "\t# story history\n",
    "\ttrain[str(i)] = history.history['loss']\n",
    "\tval[str(i)] = history.history['val_loss']\n",
    " \n",
    "# plot train and validation loss across multiple runs\n",
    "pyplot.plot(train, color='blue', label='train')\n",
    "pyplot.plot(val, color='orange', label='validation')\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resulting plot, we can see that the general trend of underfitting holds across 5 runs and is a stronger case for perhaps increasing the number of training epochs.\n",
    "\n",
    "## Summary\n",
    "In this tutorial, you discovered how to diagnose the fit of your LSTM model on your sequence prediction problem.\n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "* How to gather and plot training history of LSTM models.\n",
    "* How to diagnose an underfit, good fit, and overfit model.\n",
    "* How to develop more robust diagnostics by averaging multiple model runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
