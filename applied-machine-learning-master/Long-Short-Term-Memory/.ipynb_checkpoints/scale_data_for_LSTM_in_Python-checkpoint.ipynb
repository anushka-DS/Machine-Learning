{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Scale Data for Long Short-Term Memory Networks in Python\n",
    "The data for your sequence prediction problem probably needs to be scaled when training a neural network, such as a Long Short-Term Memory recurrent neural network.\n",
    "\n",
    "When a network is fit on unscaled data that has a range of values (e.g. quantities in the 10s to 100s) it is possible for large inputs to slow down the learning and convergence of your network and in some cases prevent the network from effectively learning your problem.\n",
    "\n",
    "In this tutorial, you will discover how to normalize and standardize your sequence prediction data and how to decide which to use for your input and output variables.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "* How to normalize and standardize sequence data in Python.\n",
    "* How to select the appropriate scaling for input and output variables.\n",
    "* Practical considerations when scaling sequence data.\n",
    "\n",
    "Letâ€™s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Overview\n",
    "This tutorial is divided into 4 parts; they are:\n",
    "\n",
    "1. Scaling Series Data\n",
    "2. Scaling Input Variables\n",
    "3. Scaling Output Variables\n",
    "4. Practical Considerations When Scaling\n",
    "\n",
    "## Scaling Series Data in Python\n",
    "There are two types of scaling of your series that you may want to consider: normalization and standardization.\n",
    "\n",
    "These can both be achieved using the scikit-learn library.\n",
    "\n",
    "### Normalize Series Data\n",
    "Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n",
    "\n",
    "Normalization requires that you know or are able to accurately estimate the minimum and maximum observable values. You may be able to estimate these values from your available data. If your time series is trending up or down, estimating these expected values may be difficult and normalization may not be the best method to use on your problem.\n",
    "\n",
    "A value is normalized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (x - min) / (max - min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the minimum and maximum values pertain to the value x being normalized.\n",
    "\n",
    "For example, for a dataset, we could guesstimate the min and max observable values as 30 and -10. We can then normalize any value, like 18.8, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (x - min) / (max - min)\n",
    "y = (18.8 - (-10)) / (30 - (-10))\n",
    "y = 28.8 / 40\n",
    "y = 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that if an x value is provided that is outside the bounds of the minimum and maximum values, that the resulting value will not be in the range of 0 and 1. You could check for these observations prior to making predictions and either remove them from the dataset or limit them to the pre-defined maximum or minimum values.\n",
    "\n",
    "You can normalize your dataset using the scikit-learn object [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).\n",
    "\n",
    "Good practice usage with the MinMaxScaler and other scaling techniques is as follows:\n",
    "\n",
    "* **Fit the scaler using available training data**. For normalization, this means the training data will be used to estimate the minimum and maximum observable values. This is done by calling the fit() function.\n",
    "* **Apply the scale to training data**. This means you can use the normalized data to train your model. This is done by calling the transform() function.\n",
    "* **Apply the scale to data going forward**. This means you can prepare new data in the future on which you want to make predictions.\n",
    "\n",
    "If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting. This can be done by calling the inverse_transform() function.\n",
    "\n",
    "Below is an example of normalizing a contrived sequence of 10 quantities.\n",
    "\n",
    "The scaler object requires data to be provided as a matrix of rows and columns. The loaded time series data is loaded as a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     10.0\n",
      "1     20.0\n",
      "2     30.0\n",
      "3     40.0\n",
      "4     50.0\n",
      "5     60.0\n",
      "6     70.0\n",
      "7     80.0\n",
      "8     90.0\n",
      "9    100.0\n",
      "dtype: float64\n",
      "Min: 10.000000, Max: 100.000000\n",
      "[[0.        ]\n",
      " [0.11111111]\n",
      " [0.22222222]\n",
      " [0.33333333]\n",
      " [0.44444444]\n",
      " [0.55555556]\n",
      " [0.66666667]\n",
      " [0.77777778]\n",
      " [0.88888889]\n",
      " [1.        ]]\n",
      "[[ 10.]\n",
      " [ 20.]\n",
      " [ 30.]\n",
      " [ 40.]\n",
      " [ 50.]\n",
      " [ 60.]\n",
      " [ 70.]\n",
      " [ 80.]\n",
      " [ 90.]\n",
      " [100.]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define contrived series\n",
    "data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "# normalize the dataset and print\n",
    "normalized = scaler.transform(values)\n",
    "print(normalized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the sequence, prints the min and max values estimated from the sequence, prints the same normalized sequence, then the values back in their original scale using the inverse transform.\n",
    "\n",
    "We can also see that the minimum and maximum values of the dataset are 10.0 and 100.0 respectively.\n",
    "\n",
    "### Standardize Series Data\n",
    "Standardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1.\n",
    "\n",
    "This can be thought of as subtracting the mean value or centering the data.\n",
    "\n",
    "Like normalization, standardization can be useful, and even required in some machine learning algorithms when your data has input values with differing scales.\n",
    "\n",
    "Standardization assumes that your observations fit a Gaussian distribution (bell curve) with a well behaved mean and standard deviation. You can still standardize your time series data if this expectation is not met, but you may not get reliable results.\n",
    "\n",
    "Standardization requires that you know or are able to accurately estimate the mean and standard deviation of observable values. You may be able to estimate these values from your training data.\n",
    "\n",
    "A value is standardized as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (x - mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the mean is calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = sum(x) / count(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the standard_deviation is calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_deviation = sqrt( sum( (x - mean)^2 ) / count(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can guesstimate a mean of 10 and a standard deviation of about 5. Using these values, we can standardize the first value of 20.7 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = (x - mean) / standard_deviation\n",
    "y = (20.7 - 10) / 5\n",
    "y = (10.7) / 5\n",
    "y = 2.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviation estimates of a dataset can be more robust to new data than the minimum and maximum.\n",
    "\n",
    "You can standardize your dataset using the scikit-learn object [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    5.5\n",
      "2    9.0\n",
      "3    2.6\n",
      "4    8.8\n",
      "5    3.0\n",
      "6    4.1\n",
      "7    7.9\n",
      "8    6.3\n",
      "dtype: float64\n",
      "Mean: 5.355556, StandardDeviation: 2.712568\n",
      "[[-1.60569456]\n",
      " [ 0.05325007]\n",
      " [ 1.34354035]\n",
      " [-1.01584758]\n",
      " [ 1.26980948]\n",
      " [-0.86838584]\n",
      " [-0.46286604]\n",
      " [ 0.93802055]\n",
      " [ 0.34817357]]\n",
      "[[1. ]\n",
      " [5.5]\n",
      " [9. ]\n",
      " [2.6]\n",
      " [8.8]\n",
      " [3. ]\n",
      " [4.1]\n",
      " [7.9]\n",
      " [6.3]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "# define contrived series\n",
    "data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "# normalize the dataset and print\n",
    "standardized = scaler.transform(values)\n",
    "print(standardized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(standardized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example prints the sequence, prints the mean and standard deviation estimated from the sequence, prints the standardized values, then prints the values back in their original scale.\n",
    "\n",
    "We can see that the estimated mean and standard deviation were about 5.3 and 2.7 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Input Variables\n",
    "The input variables are those that the network takes on the input or visible layer in order to make a prediction.\n",
    "\n",
    "A good rule of thumb is that input variables should be small values, probably in the range of 0-1 or standardized with a zero mean and a standard deviation of one.\n",
    "\n",
    "Whether input variables require scaling depends on the specifics of your problem and of each variable. Letâ€™s look at some examples.\n",
    "\n",
    "### Categorical Inputs\n",
    "You may have a sequence of categorical inputs, such as letters or statuses.\n",
    "\n",
    "Generally, categorical inputs are first integer encoded then one hot encoded. That is, a unique integer value is assigned to each distinct possible input, then a binary vector of ones and zeros is used to represent each integer value.\n",
    "\n",
    "By definition, a one hot encoding will ensure that each input is a small real value, in this case 0.0 or 1.0.\n",
    "\n",
    "### Real-Valued Inputs\n",
    "You may have a sequence of quantities as inputs, such as prices or temperatures.\n",
    "\n",
    "If the distribution of the quantity is normal, then it should be standardized, otherwise the series should be normalized. This applies if the range of quantity values is large (10s 100s, etc.) or small (0.01, 0.0001).\n",
    "\n",
    "If the quantity values are small (near 0-1) and the distribution is limited (e.g. standard deviation near 1) then perhaps you can get away with no scaling of the series.\n",
    "\n",
    "### Other Inputs\n",
    "Problems can be complex and it may not be clear how to best scale input data.\n",
    "\n",
    "If in doubt, normalize the input sequence. If you have the resources, explore modeling with the raw data, standardized data, and normalized and see if there is a beneficial difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Output Variables\n",
    "The output variable is the variable predicted by the network.\n",
    "\n",
    "You must ensure that the scale of your output variable matches the scale of the activation function (transfer function) on the output layer of your network.\n",
    "\n",
    "The following heuristics should cover most sequence prediction problems:\n",
    "\n",
    "### Binary Classification Problem\n",
    "If your problem is a binary classification problem, then the output will be class values 0 and 1. This is best modeled with a sigmoid activation function on the output layer. Output values will be real values between 0 and 1 that can be snapped to crisp values.\n",
    "\n",
    "### Multi-class Classification Problem\n",
    "If your problem is a multi-class classification problem, then the output will be a vector of binary class values between 0 and 1, one output per class value. This is best modeled with a softmax activation function on the output layer. Again, output values will be real values between 0 and 1 that can be snapped to crisp values.\n",
    "\n",
    "### Regression Problem\n",
    "If your problem is a regression problem, then the output will be a real value. This is best modeled with a linear activation function. If the distribution of the value is normal, then you can standardize the output variable. Otherwise, the output variable can be normalized.\n",
    "\n",
    "### Other Problem\n",
    "There are many other activation functions that may be used on the output layer and the specifics of your problem may add confusion.\n",
    "\n",
    "The rule of thumb is to ensure that the network outputs match the scale of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Considerations When Scaling\n",
    "There are some practical considerations when scaling sequence data.\n",
    "\n",
    "* **Estimate Coefficients**. You can estimate coefficients (min and max values for normalization or mean and standard deviation for standardization) from the training data. Inspect these first-cut estimates and use domain knowledge or domain experts to help improve these estimates so that they will be usefully correct on all data in the future.\n",
    "* **Save Coefficients**. You will need to normalize new data in the future in exactly the same way as the data used to train your model. Save the coefficients used to file and load them later when you need to scale new data when making predictions.\n",
    "* **Data Analysis**. Use data analysis to help you better understand your data. For example, a simple histogram can help you quickly get a feeling for the distribution of quantities to see if standardization would make sense.\n",
    "* **Scale Each Series**. If your problem has multiple series, treat each as a separate variable and in turn scale them separately.\n",
    "* **Scale At The Right Time**. It is important to apply any scaling transforms at the right time. For example, if you have a series of quantities that is non-stationary, it may be appropriate to scale after first making your data stationary. It would not be appropriate to scale the series after it has been transformed into a supervised learning problem as each column would be handled differently, which would be incorrect.\n",
    "* **Scale if in Doubt**. You probably do need to rescale your input and output variables. If in doubt, at least normalize your data.\n",
    "\n",
    "## Summary\n",
    "In this tutorial, you discovered how to scale your sequence prediction data when working with Long Short-Term Memory recurrent neural networks.\n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "* How to normalize and standardize sequence data in Python.\n",
    "* How to select the appropriate scaling for input and output variables.\n",
    "* Practical considerations when scaling sequence data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
