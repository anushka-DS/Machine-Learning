{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Long Short-Term Memory Networks\n",
    "The Encoder-Decoder LSTM is a recurrent neural network designed to address sequence-to-sequence problems, sometimes called seq2seq.\n",
    "\n",
    "Sequence-to-sequence prediction problems are challenging because the number of items in the input and output sequences can vary. For example, text translation and learning to execute programs are examples of seq2seq problems.\n",
    "\n",
    "In this post, you will discover the Encoder-Decoder LSTM architecture for sequence-to-sequence prediction.\n",
    "\n",
    "After completing this post, you will know:\n",
    "\n",
    "* The challenge of sequence-to-sequence prediction.\n",
    "* The Encoder-Decoder architecture and the limitation in LSTMs that it was designed to address.\n",
    "* How to implement the Encoder-Decoder LSTM model architecture in Python with Keras.\n",
    "\n",
    "Let’s get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence Prediction Problems\n",
    "Sequence prediction often involves forecasting the next value in a real valued sequence or outputting a class label for an input sequence.\n",
    "\n",
    "This is often framed as a sequence of one input time step to one output time step (e.g. one-to-one) or multiple input time steps to one output time step (many-to-one) type sequence prediction problem.\n",
    "\n",
    "There is a more challenging type of sequence prediction problem that takes a sequence as input and requires a sequence prediction as output. These are called sequence-to-sequence prediction problems, or seq2seq for short.\n",
    "\n",
    "One modeling concern that makes these problems challenging is that the length of the input and output sequences may vary. Given that there are multiple input time steps and multiple output time steps, this form of problem is referred to as many-to-many type sequence prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder LSTM Architecture\n",
    "One approach to seq2seq prediction problems that has proven very effective is called the Encoder-Decoder LSTM.\n",
    "\n",
    "This architecture is comprised of two models: one for reading the input sequence and encoding it into a fixed-length vector, and a second for decoding the fixed-length vector and outputting the predicted sequence. The use of the models in concert gives the architecture its name of Encoder-Decoder LSTM designed specifically for seq2seq problems.\n",
    "\n",
    "The Encoder-Decoder LSTM was developed for natural language processing problems where it demonstrated state-of-the-art performance, specifically in the area of text translation called statistical machine translation.\n",
    "\n",
    "The innovation of this architecture is the use of a fixed-sized internal representation in the heart of the model that input sequences are read to and output sequences are read from. For this reason, the method may be referred to as sequence embedding.\n",
    "\n",
    "In one of the first applications of the architecture to English-to-French translation, the internal representation of the encoded English phrases was visualized. The plots revealed a qualitatively meaningful learned structure of the phrases harnessed for the translation task.\n",
    "\n",
    "On the task of translation, the model was found to be more effective when the input sequence was reversed. Further, the model was shown to be effective even on very long input sequences.\n",
    "\n",
    "This approach has also been used with image inputs where a Convolutional Neural Network is used as a feature extractor on input images, which is then read by a decoder LSTM.\n",
    "\n",
    "![encoder-decoder-LSTM](Encoder-Decoder-LSTM-Model-Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Encoder-Decoder LSTMs\n",
    "The list below highlights some interesting applications of the Encoder-Decoder LSTM architecture.\n",
    "\n",
    "* Machine Translation, e.g. English to French translation of phrases.\n",
    "* Learning to Execute, e.g. calculate the outcome of small programs.\n",
    "* Image Captioning, e.g. generating a text description for images.\n",
    "* Conversational Modeling, e.g. generating answers to textual questions.\n",
    "* Movement Classification, e.g. generating a sequence of commands from a sequence of gestures.\n",
    "\n",
    "## Implement Encoder-Decoder LSTMs in Keras\n",
    "The Encoder-Decoder LSTM can be implemented directly in the Keras deep learning library.\n",
    "\n",
    "We can think of the model as being comprised of two key parts: the encoder and the decoder.\n",
    "\n",
    "First, the input sequence is shown to the network one encoded character at a time. We need an encoding level to learn the relationship between the steps in the input sequence and develop an internal representation of these relationships.\n",
    "\n",
    "One or more LSTM layers can be used to implement the encoder model. The output of this model is a fixed-size vector that represents the internal representation of the input sequence. The number of memory cells in this layer defines the length of this fixed-sized vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(..., input_shape=(...)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder must transform the learned internal representation of the input sequence into the correct output sequence.\n",
    "\n",
    "One or more LSTM layers can also be used to implement the decoder model. This model reads from the fixed sized output from the encoder model.\n",
    "\n",
    "As with the Vanilla LSTM, a Dense layer is used as the output for the network. The same weights can be used to output each time step in the output sequence by wrapping the Dense layer in a TimeDistributed wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(LSTM(..., return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(...)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a problem though.\n",
    "\n",
    "We must connect the encoder to the decoder, and they do not fit.\n",
    "\n",
    "That is, the encoder will produce a 2-dimensional matrix of outputs, where the length is defined by the number of memory cells in the layer. The decoder is an LSTM layer that expects a 3D input of [samples, time steps, features] in order to produce a decoded sequence of some different length defined by the problem.\n",
    "\n",
    "If you try to force these pieces together, you get an error indicating that the output of the decoder is 2D and 3D input to the decoder is required.\n",
    "\n",
    "We can solve this using a RepeatVector layer. This layer simply repeats the provided 2D input multiple times to create a 3D output.\n",
    "\n",
    "The RepeatVector layer can be used like an adapter to fit the encoder and decoder parts of the network together. We can configure the RepeatVector to repeat the fixed length vector one time for each time step in the output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(RepeatVector(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting this together, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(..., input_shape=(...)))\n",
    "model.add(RepeatVector(...))\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(...)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, the RepeatVector is used as an adapter to fit the fixed-sized 2D output of the encoder to the differing length and 3D input expected by the decoder. The TimeDistributed wrapper allows the same output layer to be reused for each element in the output sequence.\n",
    "\n",
    "## Summary\n",
    "In this post, you discovered the Encoder-Decoder LSTM architecture for sequence-to-sequence prediction\n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "* The challenge of sequence-to-sequence prediction.\n",
    "* The Encoder-Decoder architecture and the limitation in LSTMs that it was designed to address.\n",
    "* How to implement the Encoder-Decoder LSTM model architecture in Python with Keras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
